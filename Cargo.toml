# Context Graph - Workspace Manifest
# 13-Embedder Context Graph for semantic memory retrieval

[workspace]
resolver = "2"
members = [
    "crates/context-graph-mcp",
    "crates/context-graph-core",
    "crates/context-graph-cuda",
    "crates/context-graph-embeddings",
    "crates/context-graph-storage",
    "crates/context-graph-graph",
    "crates/context-graph-cli",
    "crates/context-graph-benchmark",
    "crates/context-graph-causal-agent",
    "crates/context-graph-graph-agent",
    "crates/context-graph-test-utils",
]

[workspace.package]
version = "0.1.0"
edition = "2021"
rust-version = "1.75"
license = "PolyForm-Noncommercial-1.0.0"
repository = "https://github.com/org/context-graph"

[workspace.dependencies]
# Async runtime
tokio = { version = "1.35", features = ["full"] }
async-trait = "0.1"

# Web framework (for SSE transport - TASK-32)
axum = "0.8"
tokio-stream = "0.1"
async-stream = "0.3"

# Serialization
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
bincode = "1.3"
toml = "0.8"

# Error handling
thiserror = "1.0"
anyhow = "1.0"

# Logging
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["json", "env-filter"] }

# Configuration
config = "0.14"

# IDs and time
uuid = { version = "1.6", features = ["v4", "v5", "serde"] }
chrono = { version = "0.4", features = ["serde"] }

# Utilities
rand = "0.8"
rand_distr = "0.4"

# GPU/ML - Candle framework (HuggingFace) for embedding models
# https://github.com/huggingface/candle
# Using 0.9.2-alpha for CUDA 13.x support (RTX 5090 Blackwell)
candle-core = { version = "0.9.2-alpha", features = ["cuda"] }
candle-nn = { version = "0.9.2-alpha", features = ["cuda"] }

# GPU/ML - llama.cpp bindings for GGUF model inference (LLM agents)
# Using llama-cpp-2 for grammar-constrained generation (GBNF)
# Supports CUDA for RTX 5090 Blackwell architecture
llama-cpp-2 = "0.1"

# Internal crates
context-graph-core = { path = "crates/context-graph-core" }
context-graph-embeddings = { path = "crates/context-graph-embeddings" }
context-graph-cuda = { path = "crates/context-graph-cuda" }

[profile.release]
lto = "thin"
codegen-units = 1
strip = true

[profile.dev]
# Faster compile times for development
opt-level = 0
debug = 1                    # Line info only (not full DWARF) - ~40-60% smaller artifacts
incremental = true
split-debuginfo = "unpacked" # Keep debuginfo separate (can be deleted independently)

[profile.dev.package."*"]
# External dependencies don't need full debug info
debug = false
