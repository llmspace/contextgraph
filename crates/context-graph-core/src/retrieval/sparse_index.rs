//! Sparse Inverted Index for E6/E13 SPLADE embeddings.
//!
//! # Overview
//!
//! This module implements a sparse inverted index for efficient recall using
//! E13 SPLADE (and optionally E6) sparse vectors. This is Stage 1 of the
//! 5-stage retrieval pipeline.
//!
//! # Algorithm
//!
//! For each term in the vocabulary, we maintain a posting list of (memory_id, weight) pairs.
//! At query time:
//! 1. Extract active terms from query sparse vector
//! 2. Union posting lists for all query terms
//! 3. Score candidates by weighted Jaccard overlap
//! 4. Return top-K candidates for subsequent stages
//!
//! # Performance Targets
//!
//! - Recall latency: <5ms
//! - Candidate count: 10K from 1M+ memories
//! - Memory: ~100MB for 1M memories
//!
//! # FAIL FAST Policy
//!
//! All errors are explicit with detailed messages. No silent fallbacks.

use std::collections::HashMap;

use parking_lot::RwLock;
use thiserror::Error;
use tracing::debug;
use uuid::Uuid;

use crate::types::fingerprint::{SparseVector, SPARSE_VOCAB_SIZE};

// ============================================================================
// CONSTANTS
// ============================================================================

/// Default number of candidates to recall in Stage 1.
pub const DEFAULT_RECALL_LIMIT: usize = 10_000;

/// Minimum posting list size to consider for pruning.
/// Very common terms (appearing in >90% of docs) are less discriminative.
const MAX_DF_RATIO: f32 = 0.9;

// ============================================================================
// ERRORS
// ============================================================================

/// Errors from sparse index operations. FAIL FAST - no recovery.
#[derive(Debug, Error, Clone, PartialEq)]
pub enum SparseIndexError {
    /// Empty sparse vector provided for indexing.
    #[error("FAIL FAST: Cannot index empty sparse vector for memory {memory_id}")]
    EmptyVector { memory_id: Uuid },

    /// Memory already exists in index (use update instead).
    #[error("FAIL FAST: Memory {memory_id} already exists in index. Use update() to modify.")]
    AlreadyExists { memory_id: Uuid },

    /// Memory not found in index.
    #[error("FAIL FAST: Memory {memory_id} not found in index")]
    NotFound { memory_id: Uuid },

    /// Term index out of bounds.
    #[error("FAIL FAST: Term index {term_id} exceeds vocabulary size {vocab_size}")]
    TermOutOfBounds { term_id: u32, vocab_size: usize },

    /// Index is locked (concurrent modification detected).
    #[error("FAIL FAST: Index lock acquisition failed - concurrent modification")]
    LockFailed,
}

/// Result type for sparse index operations.
pub type SparseIndexResult<T> = Result<T, SparseIndexError>;

// ============================================================================
// POSTING LIST
// ============================================================================

/// Single posting in an inverted index.
#[derive(Debug, Clone, Copy)]
pub struct Posting {
    /// Memory UUID this posting refers to.
    pub memory_id: Uuid,
    /// Weight/score of this term in this memory.
    pub weight: f32,
}

impl Posting {
    /// Create a new posting.
    #[inline]
    pub fn new(memory_id: Uuid, weight: f32) -> Self {
        Self { memory_id, weight }
    }
}

/// Posting list for a single term.
#[derive(Debug, Clone, Default)]
pub struct PostingList {
    /// Sorted by memory_id for efficient merge operations.
    postings: Vec<Posting>,
}

impl PostingList {
    /// Create an empty posting list.
    pub fn new() -> Self {
        Self {
            postings: Vec::new(),
        }
    }

    /// Add a posting to this list.
    /// Maintains sorted order by memory_id.
    pub fn add(&mut self, posting: Posting) {
        // Binary search to find insertion point (maintain sorted order)
        match self.postings.binary_search_by(|p| p.memory_id.cmp(&posting.memory_id)) {
            Ok(idx) => {
                // Memory already exists - update weight
                self.postings[idx].weight = posting.weight;
            }
            Err(idx) => {
                // Insert at correct position to maintain sorted order
                self.postings.insert(idx, posting);
            }
        }
    }

    /// Remove a posting by memory_id.
    pub fn remove(&mut self, memory_id: Uuid) -> bool {
        if let Ok(idx) = self.postings.binary_search_by(|p| p.memory_id.cmp(&memory_id)) {
            self.postings.remove(idx);
            true
        } else {
            false
        }
    }

    /// Number of postings in this list (document frequency).
    #[inline]
    pub fn len(&self) -> usize {
        self.postings.len()
    }

    /// Check if posting list is empty.
    #[inline]
    pub fn is_empty(&self) -> bool {
        self.postings.is_empty()
    }

    /// Iterate over postings.
    #[inline]
    pub fn iter(&self) -> impl Iterator<Item = &Posting> {
        self.postings.iter()
    }
}

// ============================================================================
// RECALL RESULT
// ============================================================================

/// Result from sparse index recall operation.
#[derive(Debug, Clone)]
pub struct RecallCandidate {
    /// Memory UUID.
    pub memory_id: Uuid,
    /// Recall score (weighted term overlap).
    pub score: f32,
    /// Number of query terms that matched this document.
    pub matching_terms: u32,
}

/// Recall statistics for monitoring and debugging.
#[derive(Debug, Clone, Default)]
pub struct RecallStats {
    /// Number of query terms used.
    pub query_terms: usize,
    /// Total posting list accesses.
    pub posting_accesses: usize,
    /// Unique candidates before ranking.
    pub unique_candidates: usize,
    /// Candidates returned after top-K.
    pub returned_candidates: usize,
    /// Recall latency in microseconds.
    pub latency_us: u64,
}

// ============================================================================
// SPARSE INVERTED INDEX
// ============================================================================

/// Sparse inverted index for E6/E13 SPLADE embeddings.
///
/// Thread-safe via internal RwLock. Supports concurrent reads, exclusive writes.
pub struct SparseInvertedIndex {
    /// Posting lists indexed by term ID (vocabulary index).
    /// Using RwLock for thread-safe access.
    posting_lists: RwLock<HashMap<u16, PostingList>>,

    /// Total number of indexed memories.
    doc_count: RwLock<usize>,

    /// Memory ID to sparse vector mapping (for deletion support).
    /// Maps memory_id -> Vec<term_id> (active terms for this memory)
    memory_terms: RwLock<HashMap<Uuid, Vec<u16>>>,
}

impl SparseInvertedIndex {
    /// Create a new empty sparse inverted index.
    pub fn new() -> Self {
        Self {
            posting_lists: RwLock::new(HashMap::with_capacity(SPARSE_VOCAB_SIZE / 10)),
            doc_count: RwLock::new(0),
            memory_terms: RwLock::new(HashMap::new()),
        }
    }

    /// Create with pre-allocated capacity for expected document count.
    pub fn with_capacity(expected_docs: usize) -> Self {
        // Estimate ~100 unique terms per doc on average
        let estimated_unique_terms = (expected_docs as f64 * 0.1).min(SPARSE_VOCAB_SIZE as f64) as usize;

        Self {
            posting_lists: RwLock::new(HashMap::with_capacity(estimated_unique_terms)),
            doc_count: RwLock::new(0),
            memory_terms: RwLock::new(HashMap::with_capacity(expected_docs)),
        }
    }

    /// Index a sparse vector for a memory.
    ///
    /// # Arguments
    /// * `memory_id` - UUID of the memory
    /// * `sparse` - E6 or E13 sparse vector
    ///
    /// # FAIL FAST Errors
    /// * `EmptyVector` - Cannot index empty sparse vector
    /// * `AlreadyExists` - Memory already indexed (use update)
    pub fn index(&self, memory_id: Uuid, sparse: &SparseVector) -> SparseIndexResult<()> {
        if sparse.is_empty() {
            return Err(SparseIndexError::EmptyVector { memory_id });
        }

        // Check if already exists
        {
            let terms_guard = self.memory_terms.read();
            if terms_guard.contains_key(&memory_id) {
                return Err(SparseIndexError::AlreadyExists { memory_id });
            }
        }

        // Acquire write locks (parking_lot: non-poisoning, always succeeds)
        let mut posting_guard = self.posting_lists.write();
        let mut terms_guard = self.memory_terms.write();
        let mut count_guard = self.doc_count.write();

        // Double-check after acquiring lock
        if terms_guard.contains_key(&memory_id) {
            return Err(SparseIndexError::AlreadyExists { memory_id });
        }

        // Index each term
        let mut indexed_terms = Vec::with_capacity(sparse.nnz());
        for (&term_id, &weight) in sparse.indices.iter().zip(sparse.values.iter()) {
            let posting = Posting::new(memory_id, weight);

            posting_guard
                .entry(term_id)
                .or_default()
                .add(posting);

            indexed_terms.push(term_id);
        }

        // Store memory's terms for later deletion
        terms_guard.insert(memory_id, indexed_terms);
        *count_guard += 1;

        debug!(
            memory_id = %memory_id,
            terms_indexed = sparse.nnz(),
            total_docs = *count_guard,
            "Indexed sparse vector"
        );

        Ok(())
    }

    /// Remove a memory from the index.
    ///
    /// # FAIL FAST Errors
    /// * `NotFound` - Memory not in index
    pub fn remove(&self, memory_id: Uuid) -> SparseIndexResult<()> {
        let mut posting_guard = self.posting_lists.write();
        let mut terms_guard = self.memory_terms.write();
        let mut count_guard = self.doc_count.write();

        // Get terms for this memory
        let terms = terms_guard
            .remove(&memory_id)
            .ok_or(SparseIndexError::NotFound { memory_id })?;

        // Remove from each posting list
        for term_id in terms {
            if let Some(posting_list) = posting_guard.get_mut(&term_id) {
                posting_list.remove(memory_id);

                // Remove empty posting lists to save memory
                if posting_list.is_empty() {
                    posting_guard.remove(&term_id);
                }
            }
        }

        *count_guard = count_guard.saturating_sub(1);

        debug!(
            memory_id = %memory_id,
            remaining_docs = *count_guard,
            "Removed from sparse index"
        );

        Ok(())
    }

    /// Update a memory's sparse vector in the index.
    ///
    /// Equivalent to remove() + index() but atomic.
    pub fn update(&self, memory_id: Uuid, sparse: &SparseVector) -> SparseIndexResult<()> {
        if sparse.is_empty() {
            return Err(SparseIndexError::EmptyVector { memory_id });
        }

        let mut posting_guard = self.posting_lists.write();
        let mut terms_guard = self.memory_terms.write();

        // Remove old terms if exists
        if let Some(old_terms) = terms_guard.remove(&memory_id) {
            for term_id in old_terms {
                if let Some(posting_list) = posting_guard.get_mut(&term_id) {
                    posting_list.remove(memory_id);
                    if posting_list.is_empty() {
                        posting_guard.remove(&term_id);
                    }
                }
            }
        }

        // Index new terms
        let mut indexed_terms = Vec::with_capacity(sparse.nnz());
        for (&term_id, &weight) in sparse.indices.iter().zip(sparse.values.iter()) {
            let posting = Posting::new(memory_id, weight);

            posting_guard
                .entry(term_id)
                .or_default()
                .add(posting);

            indexed_terms.push(term_id);
        }

        terms_guard.insert(memory_id, indexed_terms);

        Ok(())
    }

    /// Recall candidates using a query sparse vector.
    ///
    /// This is Stage 1 of the retrieval pipeline.
    ///
    /// # Algorithm
    ///
    /// 1. For each query term, retrieve posting list
    /// 2. Accumulate weighted scores for each candidate
    /// 3. Score = Σ(query_weight × doc_weight × IDF_weight)
    /// 4. Return top-K candidates sorted by score
    ///
    /// # Arguments
    /// * `query` - Query sparse vector (E13 SPLADE)
    /// * `limit` - Maximum candidates to return (default: 10,000)
    ///
    /// # Returns
    /// * `Vec<RecallCandidate>` - Top candidates sorted by score (descending)
    /// * `RecallStats` - Statistics for monitoring
    pub fn recall(&self, query: &SparseVector, limit: usize) -> (Vec<RecallCandidate>, RecallStats) {
        let start = std::time::Instant::now();
        let limit = if limit == 0 { DEFAULT_RECALL_LIMIT } else { limit };

        if query.is_empty() {
            return (Vec::new(), RecallStats::default());
        }

        let posting_guard = self.posting_lists.read();
        let doc_count = *self.doc_count.read();

        // Accumulate scores for each candidate
        let mut candidate_scores: HashMap<Uuid, (f32, u32)> = HashMap::new();
        let mut posting_accesses = 0;

        // Process each query term
        for (&term_id, &query_weight) in query.indices.iter().zip(query.values.iter()) {
            if let Some(posting_list) = posting_guard.get(&term_id) {
                posting_accesses += 1;

                // Compute IDF weight: log((N + 1) / (df + 1)) + 1
                // The +1 smoothing ensures IDF is always positive, even with single documents
                // This is the standard smoothed IDF formula used in modern IR systems
                let df = posting_list.len() as f32;
                let idf = if doc_count > 0 && df > 0.0 {
                    ((doc_count as f32 + 1.0) / (df + 1.0)).ln() + 1.0
                } else {
                    1.0
                };

                // Skip very common terms (>90% of docs) - only for large corpora
                // For small corpora, this check can filter out valid matches
                if doc_count >= 1000 && df / (doc_count as f32) > MAX_DF_RATIO {
                    continue;
                }

                // Accumulate scores
                for posting in posting_list.iter() {
                    let score = query_weight * posting.weight * idf;
                    let entry = candidate_scores
                        .entry(posting.memory_id)
                        .or_insert((0.0, 0));
                    entry.0 += score;
                    entry.1 += 1;
                }
            }
        }

        let unique_candidates = candidate_scores.len();

        // Convert to candidates and sort by score
        let mut candidates: Vec<RecallCandidate> = candidate_scores
            .into_iter()
            .map(|(memory_id, (score, matching_terms))| RecallCandidate {
                memory_id,
                score,
                matching_terms,
            })
            .collect();

        // Sort by descending score
        candidates.sort_by(|a, b| b.score.partial_cmp(&a.score).unwrap_or(std::cmp::Ordering::Equal));

        // Truncate to limit
        candidates.truncate(limit);
        let returned_candidates = candidates.len();

        let stats = RecallStats {
            query_terms: query.nnz(),
            posting_accesses,
            unique_candidates,
            returned_candidates,
            latency_us: start.elapsed().as_micros() as u64,
        };

        debug!(
            query_terms = stats.query_terms,
            unique_candidates = stats.unique_candidates,
            returned_candidates = stats.returned_candidates,
            latency_us = stats.latency_us,
            "Sparse recall complete"
        );

        (candidates, stats)
    }

    /// Get the number of indexed memories.
    pub fn len(&self) -> usize {
        *self.doc_count.read()
    }

    /// Check if index is empty.
    pub fn is_empty(&self) -> bool {
        self.len() == 0
    }

    /// Get the number of unique terms in the index.
    pub fn term_count(&self) -> usize {
        self.posting_lists.read().len()
    }

    /// Check if a memory is indexed.
    pub fn contains(&self, memory_id: Uuid) -> bool {
        self.memory_terms.read().contains_key(&memory_id)
    }

    /// Get document frequency for a term.
    pub fn get_df(&self, term_id: u16) -> usize {
        self.posting_lists
            .read()
            .get(&term_id)
            .map(|pl| pl.len())
            .unwrap_or(0)
    }

    /// Clear all indexed data.
    pub fn clear(&self) {
        let mut pl = self.posting_lists.write();
        let mut mt = self.memory_terms.write();
        let mut dc = self.doc_count.write();
        pl.clear();
        pl.shrink_to_fit(); // Release allocated HashMap capacity
        mt.clear();
        mt.shrink_to_fit(); // Release allocated HashMap capacity
        *dc = 0;
    }

    /// Estimated memory usage in bytes for monitoring.
    ///
    /// Includes posting lists (20 bytes per posting) and reverse term index.
    pub fn estimated_memory_bytes(&self) -> usize {
        let pl = self.posting_lists.read();
        let mt = self.memory_terms.read();

        let posting_bytes: usize = pl.values().map(|p| p.len() * 20).sum();
        let terms_bytes: usize = mt.values().map(|v| v.len() * 2 + 16).sum(); // 2 per u16 + 16 UUID
        let overhead = pl.capacity() * 24 + mt.capacity() * 32; // HashMap overhead

        posting_bytes + terms_bytes + overhead
    }
}

impl Default for SparseInvertedIndex {
    fn default() -> Self {
        Self::new()
    }
}

// ============================================================================
// TESTS
// ============================================================================

#[cfg(test)]
mod tests {
    use super::*;

    /// Create a test sparse vector with known terms.
    fn create_test_sparse(terms: &[(u16, f32)]) -> SparseVector {
        let mut indices: Vec<u16> = terms.iter().map(|(i, _)| *i).collect();
        let mut values: Vec<f32> = terms.iter().map(|(_, v)| *v).collect();

        // Sort by indices (required by SparseVector)
        let mut pairs: Vec<_> = indices.into_iter().zip(values).collect();
        pairs.sort_by_key(|(i, _)| *i);

        indices = pairs.iter().map(|(i, _)| *i).collect();
        values = pairs.iter().map(|(_, v)| *v).collect();

        SparseVector::new(indices, values).unwrap()
    }

    // ========================================================================
    // BASIC FUNCTIONALITY TESTS
    // ========================================================================

    #[test]
    fn test_index_and_recall() {
        println!("=== TEST: Index and Recall ===");

        let index = SparseInvertedIndex::new();

        // Index three memories with overlapping terms
        let id1 = Uuid::new_v4();
        let id2 = Uuid::new_v4();
        let id3 = Uuid::new_v4();

        // Memory 1: terms 10, 20, 30
        let sparse1 = create_test_sparse(&[(10, 1.0), (20, 0.5), (30, 0.3)]);
        index.index(id1, &sparse1).unwrap();

        // Memory 2: terms 20, 30, 40
        let sparse2 = create_test_sparse(&[(20, 0.8), (30, 0.6), (40, 0.4)]);
        index.index(id2, &sparse2).unwrap();

        // Memory 3: terms 50, 60 (no overlap with query)
        let sparse3 = create_test_sparse(&[(50, 1.0), (60, 1.0)]);
        index.index(id3, &sparse3).unwrap();

        println!("[BEFORE RECALL] Indexed {} memories", index.len());

        // Query with terms 20, 30 (should match id1 and id2)
        let query = create_test_sparse(&[(20, 1.0), (30, 1.0)]);
        let (candidates, stats) = index.recall(&query, 10);

        println!(
            "[AFTER RECALL] Found {} candidates in {}us",
            candidates.len(),
            stats.latency_us
        );

        // Verify results
        assert_eq!(candidates.len(), 2, "Should find 2 matching memories");

        // Both id1 and id2 should be in results
        let result_ids: Vec<_> = candidates.iter().map(|c| c.memory_id).collect();
        assert!(result_ids.contains(&id1), "id1 should be in results");
        assert!(result_ids.contains(&id2), "id2 should be in results");
        assert!(!result_ids.contains(&id3), "id3 should NOT be in results");

        println!("[VERIFIED] Index and recall works correctly");
    }

    #[test]
    fn test_index_empty_vector_fails() {
        println!("=== TEST: Index Empty Vector Fails ===");

        let index = SparseInvertedIndex::new();
        let id = Uuid::new_v4();
        let empty = SparseVector::empty();

        let result = index.index(id, &empty);
        assert!(matches!(result, Err(SparseIndexError::EmptyVector { .. })));

        println!("[VERIFIED] Empty vector indexing fails fast");
    }

    #[test]
    fn test_index_duplicate_fails() {
        println!("=== TEST: Index Duplicate Fails ===");

        let index = SparseInvertedIndex::new();
        let id = Uuid::new_v4();
        let sparse = create_test_sparse(&[(10, 1.0)]);

        // First index succeeds
        assert!(index.index(id, &sparse).is_ok());

        // Second index fails
        let result = index.index(id, &sparse);
        assert!(matches!(result, Err(SparseIndexError::AlreadyExists { .. })));

        println!("[VERIFIED] Duplicate indexing fails fast");
    }

    #[test]
    fn test_remove() {
        println!("=== TEST: Remove ===");

        let index = SparseInvertedIndex::new();
        let id = Uuid::new_v4();
        let sparse = create_test_sparse(&[(10, 1.0), (20, 0.5)]);

        // Index
        index.index(id, &sparse).unwrap();
        assert_eq!(index.len(), 1);
        assert!(index.contains(id));

        // Remove
        index.remove(id).unwrap();
        assert_eq!(index.len(), 0);
        assert!(!index.contains(id));

        // Query should return empty
        let query = create_test_sparse(&[(10, 1.0)]);
        let (candidates, _) = index.recall(&query, 10);
        assert!(candidates.is_empty());

        println!("[VERIFIED] Remove works correctly");
    }

    #[test]
    fn test_remove_not_found() {
        println!("=== TEST: Remove Not Found ===");

        let index = SparseInvertedIndex::new();
        let id = Uuid::new_v4();

        let result = index.remove(id);
        assert!(matches!(result, Err(SparseIndexError::NotFound { .. })));

        println!("[VERIFIED] Remove not found fails fast");
    }

    #[test]
    fn test_update() {
        println!("=== TEST: Update ===");

        let index = SparseInvertedIndex::new();
        let id = Uuid::new_v4();

        // Initial index with terms 10, 20
        let sparse1 = create_test_sparse(&[(10, 1.0), (20, 0.5)]);
        index.index(id, &sparse1).unwrap();

        // Update to terms 30, 40
        let sparse2 = create_test_sparse(&[(30, 0.8), (40, 0.6)]);
        index.update(id, &sparse2).unwrap();

        // Query old terms - should not find
        let query_old = create_test_sparse(&[(10, 1.0)]);
        let (candidates, _) = index.recall(&query_old, 10);
        assert!(candidates.is_empty(), "Old terms should not match");

        // Query new terms - should find
        let query_new = create_test_sparse(&[(30, 1.0)]);
        let (candidates, _) = index.recall(&query_new, 10);
        assert_eq!(candidates.len(), 1, "New terms should match");
        assert_eq!(candidates[0].memory_id, id);

        println!("[VERIFIED] Update works correctly");
    }

    // ========================================================================
    // RECALL SCORING TESTS
    // ========================================================================

    #[test]
    fn test_recall_scoring_order() {
        println!("=== TEST: Recall Scoring Order ===");

        let index = SparseInvertedIndex::new();

        // Memory with high weights
        let id_high = Uuid::new_v4();
        let sparse_high = create_test_sparse(&[(10, 1.0), (20, 1.0), (30, 1.0)]);
        index.index(id_high, &sparse_high).unwrap();

        // Memory with low weights
        let id_low = Uuid::new_v4();
        let sparse_low = create_test_sparse(&[(10, 0.1), (20, 0.1), (30, 0.1)]);
        index.index(id_low, &sparse_low).unwrap();

        // Query
        let query = create_test_sparse(&[(10, 1.0), (20, 1.0), (30, 1.0)]);
        let (candidates, _) = index.recall(&query, 10);

        assert_eq!(candidates.len(), 2);
        // High-weight memory should rank first
        assert_eq!(candidates[0].memory_id, id_high, "High-weight should rank first");
        assert!(candidates[0].score > candidates[1].score, "Scores should be ordered");

        println!(
            "Scores: high={:.4}, low={:.4}",
            candidates[0].score, candidates[1].score
        );
        println!("[VERIFIED] Recall scoring order is correct");
    }

    #[test]
    fn test_recall_limit() {
        println!("=== TEST: Recall Limit ===");

        let index = SparseInvertedIndex::new();

        // Index 100 memories with the same term
        for i in 0..100 {
            let id = Uuid::new_v4();
            let sparse = create_test_sparse(&[(10, (i as f32) / 100.0 + 0.01)]);
            index.index(id, &sparse).unwrap();
        }

        // Query with limit 10
        let query = create_test_sparse(&[(10, 1.0)]);
        let (candidates, stats) = index.recall(&query, 10);

        assert_eq!(candidates.len(), 10);
        assert_eq!(stats.unique_candidates, 100);
        assert_eq!(stats.returned_candidates, 10);

        // Verify top results are highest scoring
        for i in 1..candidates.len() {
            assert!(
                candidates[i - 1].score >= candidates[i].score,
                "Results should be sorted by score"
            );
        }

        println!("[VERIFIED] Recall limit works correctly");
    }

    #[test]
    fn test_recall_empty_query() {
        println!("=== TEST: Recall Empty Query ===");

        let index = SparseInvertedIndex::new();

        let id = Uuid::new_v4();
        let sparse = create_test_sparse(&[(10, 1.0)]);
        index.index(id, &sparse).unwrap();

        let empty = SparseVector::empty();
        let (candidates, stats) = index.recall(&empty, 10);

        assert!(candidates.is_empty());
        assert_eq!(stats.query_terms, 0);

        println!("[VERIFIED] Empty query returns empty results");
    }

    #[test]
    fn test_recall_no_match() {
        println!("=== TEST: Recall No Match ===");

        let index = SparseInvertedIndex::new();

        let id = Uuid::new_v4();
        let sparse = create_test_sparse(&[(10, 1.0), (20, 0.5)]);
        index.index(id, &sparse).unwrap();

        // Query with different terms
        let query = create_test_sparse(&[(100, 1.0), (200, 1.0)]);
        let (candidates, stats) = index.recall(&query, 10);

        assert!(candidates.is_empty());
        assert_eq!(stats.posting_accesses, 0);

        println!("[VERIFIED] No match returns empty results");
    }

    // ========================================================================
    // STATISTICS TESTS
    // ========================================================================

    #[test]
    fn test_index_statistics() {
        println!("=== TEST: Index Statistics ===");

        let index = SparseInvertedIndex::new();
        assert_eq!(index.len(), 0);
        assert!(index.is_empty());
        assert_eq!(index.term_count(), 0);

        // Index a memory
        let id = Uuid::new_v4();
        let sparse = create_test_sparse(&[(10, 1.0), (20, 0.5), (30, 0.3)]);
        index.index(id, &sparse).unwrap();

        assert_eq!(index.len(), 1);
        assert!(!index.is_empty());
        assert_eq!(index.term_count(), 3);
        assert!(index.contains(id));
        assert_eq!(index.get_df(10), 1);
        assert_eq!(index.get_df(99), 0); // Non-existent term

        println!("[VERIFIED] Index statistics are correct");
    }

    #[test]
    fn test_clear() {
        println!("=== TEST: Clear ===");

        let index = SparseInvertedIndex::new();

        for _ in 0..10 {
            let id = Uuid::new_v4();
            let sparse = create_test_sparse(&[(10, 1.0)]);
            index.index(id, &sparse).unwrap();
        }

        assert_eq!(index.len(), 10);

        index.clear();

        assert_eq!(index.len(), 0);
        assert!(index.is_empty());
        assert_eq!(index.term_count(), 0);

        println!("[VERIFIED] Clear works correctly");
    }

    // ========================================================================
    // PERFORMANCE TESTS
    // ========================================================================

    #[test]
    fn test_recall_performance() {
        println!("=== TEST: Recall Performance ===");

        let index = SparseInvertedIndex::with_capacity(10_000);

        // Index 10,000 memories
        println!("[SETUP] Indexing 10,000 memories...");
        let index_start = std::time::Instant::now();

        for i in 0..10_000 {
            let id = Uuid::new_v4();
            // Create sparse vector with ~50 terms each
            let terms: Vec<_> = (0..50)
                .map(|j| ((i * 50 + j) as u16 % 30000, ((j as f32) / 50.0) + 0.1))
                .collect();
            let sparse = create_test_sparse(&terms);
            index.index(id, &sparse).unwrap();
        }

        let index_time = index_start.elapsed();
        println!(
            "[SETUP] Indexed {} memories in {:?}",
            index.len(),
            index_time
        );

        // Perform recall
        let query_terms: Vec<_> = (0..100)
            .map(|i| (i as u16 * 300, 0.5))
            .collect();
        let query = create_test_sparse(&query_terms);

        let recall_start = std::time::Instant::now();
        let (_candidates, stats) = index.recall(&query, DEFAULT_RECALL_LIMIT);
        let recall_time = recall_start.elapsed();

        println!("Recall Statistics:");
        println!("  - Query terms: {}", stats.query_terms);
        println!("  - Posting accesses: {}", stats.posting_accesses);
        println!("  - Unique candidates: {}", stats.unique_candidates);
        println!("  - Returned candidates: {}", stats.returned_candidates);
        println!("  - Latency: {}us", stats.latency_us);
        println!("  - Actual time: {:?}", recall_time);

        // Performance target: <5ms (5000us)
        assert!(
            stats.latency_us < 5_000,
            "Recall should be <5ms, got {}us",
            stats.latency_us
        );

        println!("[VERIFIED] Recall performance meets target (<5ms)");
    }

    // ========================================================================
    // SYNTHETIC VERIFICATION TESTS
    // ========================================================================

    #[test]
    fn test_synthetic_known_scores() {
        println!("=== TEST: Synthetic Known Scores ===");

        let index = SparseInvertedIndex::new();

        // Index a single memory with known weights
        let id = Uuid::new_v4();
        let sparse = create_test_sparse(&[(100, 0.5), (200, 0.8)]);
        index.index(id, &sparse).unwrap();

        println!("STATE BEFORE: Indexed memory with terms {{100: 0.5, 200: 0.8}}");

        // Query with weights
        let query = create_test_sparse(&[(100, 1.0), (200, 1.0)]);
        let (candidates, _stats) = index.recall(&query, 10);

        println!("STATE AFTER: Found {} candidates", candidates.len());
        println!("  - First candidate score: {}", candidates[0].score);
        println!("  - Matching terms: {}", candidates[0].matching_terms);

        // Verify
        assert_eq!(candidates.len(), 1);
        assert_eq!(candidates[0].memory_id, id);
        assert_eq!(candidates[0].matching_terms, 2);
        // Score = (1.0 * 0.5 * idf) + (1.0 * 0.8 * idf)
        // With 1 doc, IDF = ln(1/1) = 0, so we need to check the actual formula
        // In our implementation, IDF = max(0, ln(N/df)) which is 0 for single doc
        // But we also add a minimum IDF of 1.0 when doc_count > 0
        assert!(candidates[0].score > 0.0, "Score should be positive");

        println!("[VERIFIED] Synthetic scores are correct");
    }

}
