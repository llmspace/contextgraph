//! E6 Sparse benchmark runner for evaluating sparse embedder effectiveness.
//!
//! This runner executes comprehensive E6 benchmarks and produces metrics
//! for keyword precision, sparsity analysis, and ablation studies.
//!
//! ## Benchmark Categories
//!
//! 1. **Keyword Precision**: Exact term matching accuracy
//! 2. **Retrieval Quality**: MRR, P@K, R@K, NDCG
//! 3. **Sparsity Analysis**: Active terms, sparsity ratio, weight distribution
//! 4. **Ablation**: E6 contribution vs E1-only baseline
//! 5. **Threshold Sweep**: Find optimal sparsification threshold

use std::collections::HashMap;
use std::time::Instant;

use serde::{Deserialize, Serialize};

use crate::datasets::sparse::{
    E6SparseBenchmarkDataset, E6SparseDatasetConfig, E6SparseDatasetGenerator,
};
use crate::metrics::sparse::{
    compute_e6_ablation_metrics, compute_keyword_precision_metrics,
    compute_retrieval_quality_metrics, compute_sparsity_analysis_metrics, E6AblationMetrics,
    E6SparseMetrics, KeywordPrecisionMetrics, KeywordQueryResult, RetrievalQualityMetrics,
    SparsityAnalysisMetrics, SparseVectorStats,
};

/// Configuration for E6 sparse benchmarks.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct E6SparseBenchmarkConfig {
    /// Dataset configuration.
    pub dataset: E6SparseDatasetConfig,

    /// K values for retrieval metrics (MRR@K, P@K, etc.).
    pub k_values: Vec<usize>,

    /// Run ablation study (compare with/without E6).
    pub run_ablation: bool,

    /// Run threshold sweep to find optimal sparsification.
    pub run_threshold_sweep: bool,

    /// Threshold values to test in sweep.
    pub threshold_values: Vec<f32>,

    /// Simulate real embeddings (if false, uses synthetic data).
    pub simulate_embeddings: bool,
}

impl Default for E6SparseBenchmarkConfig {
    fn default() -> Self {
        Self {
            dataset: E6SparseDatasetConfig::default(),
            k_values: vec![1, 5, 10, 20],
            run_ablation: true,
            run_threshold_sweep: false,
            threshold_values: vec![0.005, 0.01, 0.02, 0.05, 0.1],
            simulate_embeddings: true,
        }
    }
}

/// Results from an E6 sparse benchmark run.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct E6SparseBenchmarkResults {
    /// E6 sparse metrics.
    pub metrics: E6SparseMetrics,

    /// Threshold sweep results (if enabled).
    pub threshold_sweep: Option<ThresholdSweepResults>,

    /// Performance timings.
    pub timings: E6BenchmarkTimings,

    /// Configuration used.
    pub config: E6SparseBenchmarkConfig,

    /// Dataset statistics.
    pub dataset_stats: E6DatasetStats,
}

/// Threshold sweep results.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ThresholdSweepResults {
    /// Per-threshold metrics.
    pub per_threshold: HashMap<String, ThresholdMetrics>,

    /// Optimal threshold found.
    pub optimal_threshold: f32,

    /// Recommendation string.
    pub recommendation: String,
}

/// Metrics for a single threshold value.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ThresholdMetrics {
    /// Threshold value.
    pub threshold: f32,

    /// Average active terms at this threshold.
    pub avg_active_terms: f64,

    /// Sparsity ratio at this threshold.
    pub sparsity_ratio: f64,

    /// MRR@10 at this threshold.
    pub mrr_at_10: f64,

    /// Precision@10 at this threshold.
    pub precision_at_10: f64,

    /// Embedding latency (ms).
    pub embed_latency_ms: f64,

    /// Search latency (ms).
    pub search_latency_ms: f64,

    /// Quality score (combined metric).
    pub quality_score: f64,
}

/// Benchmark timings.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct E6BenchmarkTimings {
    /// Total benchmark duration (ms).
    pub total_ms: u64,

    /// Dataset generation time (ms).
    pub dataset_generation_ms: u64,

    /// Keyword precision benchmark time (ms).
    pub keyword_precision_ms: u64,

    /// Retrieval quality benchmark time (ms).
    pub retrieval_quality_ms: u64,

    /// Sparsity analysis time (ms).
    pub sparsity_analysis_ms: u64,

    /// Ablation study time (ms).
    pub ablation_ms: Option<u64>,

    /// Threshold sweep time (ms).
    pub threshold_sweep_ms: Option<u64>,
}

/// Dataset statistics for reporting.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct E6DatasetStats {
    pub total_documents: usize,
    pub total_queries: usize,
    pub anti_example_count: usize,
    pub unique_keywords: usize,
    pub domains_used: Vec<String>,
}

/// Runner for E6 sparse benchmarks.
pub struct E6SparseBenchmarkRunner {
    config: E6SparseBenchmarkConfig,
}

impl E6SparseBenchmarkRunner {
    /// Create a new runner with the given configuration.
    pub fn new(config: E6SparseBenchmarkConfig) -> Self {
        Self { config }
    }

    /// Run all E6 sparse benchmarks.
    pub fn run(&self) -> E6SparseBenchmarkResults {
        let start = Instant::now();

        // Generate dataset
        let gen_start = Instant::now();
        let mut generator = E6SparseDatasetGenerator::new(self.config.dataset.clone());
        let dataset = generator.generate();
        let gen_time = gen_start.elapsed();

        // Run keyword precision benchmarks
        let kp_start = Instant::now();
        let (keyword_results, keyword_precision) = self.run_keyword_precision_benchmarks(&dataset);
        let kp_time = kp_start.elapsed();

        // Run retrieval quality benchmarks
        let rq_start = Instant::now();
        let retrieval_quality = self.run_retrieval_quality_benchmarks(&keyword_results);
        let rq_time = rq_start.elapsed();

        // Run sparsity analysis
        let sp_start = Instant::now();
        let (sparse_vectors, sparsity_analysis) = self.run_sparsity_analysis(&dataset);
        let sp_time = sp_start.elapsed();

        // Run ablation study if enabled
        let (ablation, ablation_time) = if self.config.run_ablation {
            let ab_start = Instant::now();
            let ablation = self.run_ablation_study(&dataset, &keyword_results);
            (Some(ablation), Some(ab_start.elapsed().as_millis() as u64))
        } else {
            (None, None)
        };

        // Run threshold sweep if enabled
        let (threshold_sweep, sweep_time) = if self.config.run_threshold_sweep {
            let sw_start = Instant::now();
            let sweep = self.run_threshold_sweep(&dataset);
            (Some(sweep), Some(sw_start.elapsed().as_millis() as u64))
        } else {
            (None, None)
        };

        // Compile metrics
        let ablation_metrics = ablation.clone().unwrap_or_default();

        let metrics = E6SparseMetrics {
            keyword_precision,
            retrieval_quality,
            sparsity_analysis,
            ablation: ablation_metrics,
            query_count: dataset.queries.len(),
        };

        let stats = dataset.stats();

        E6SparseBenchmarkResults {
            metrics,
            threshold_sweep,
            timings: E6BenchmarkTimings {
                total_ms: start.elapsed().as_millis() as u64,
                dataset_generation_ms: gen_time.as_millis() as u64,
                keyword_precision_ms: kp_time.as_millis() as u64,
                retrieval_quality_ms: rq_time.as_millis() as u64,
                sparsity_analysis_ms: sp_time.as_millis() as u64,
                ablation_ms: ablation_time,
                threshold_sweep_ms: sweep_time,
            },
            config: self.config.clone(),
            dataset_stats: E6DatasetStats {
                total_documents: stats.total_documents,
                total_queries: stats.total_queries,
                anti_example_count: stats.anti_example_count,
                unique_keywords: stats.unique_keywords,
                domains_used: stats
                    .docs_by_domain
                    .keys()
                    .map(|d| format!("{:?}", d))
                    .collect(),
            },
        }
    }

    fn run_keyword_precision_benchmarks(
        &self,
        dataset: &E6SparseBenchmarkDataset,
    ) -> (Vec<KeywordQueryResult>, KeywordPrecisionMetrics) {
        let mut results = Vec::new();

        for query in &dataset.queries {
            // Simulate ranking based on keyword presence
            // In real implementation, this would use actual E6 embeddings
            let mut doc_scores: Vec<(uuid::Uuid, f32)> = dataset
                .documents
                .iter()
                .map(|doc| {
                    // Simulate E6 sparse similarity
                    let score = self.simulate_e6_score(doc, &query.keyword);
                    (doc.id, score)
                })
                .collect();

            doc_scores.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap_or(std::cmp::Ordering::Equal));

            results.push(KeywordQueryResult {
                query_id: query.id,
                keyword: query.keyword.clone(),
                domain: format!("{:?}", query.domain),
                ranked_docs: doc_scores.iter().map(|(id, _)| *id).collect(),
                relevant_docs: query.expected_top.clone(),
                anti_relevant_docs: query.anti_expected.clone(),
                scores: doc_scores.iter().map(|(_, s)| *s).collect(),
            });
        }

        let metrics = compute_keyword_precision_metrics(&results, &self.config.k_values);

        (results, metrics)
    }

    fn simulate_e6_score(
        &self,
        doc: &crate::datasets::sparse::SparseDocument,
        keyword: &str,
    ) -> f32 {
        // Simulate E6 sparse similarity
        // Higher score if document contains the keyword
        let keyword_lower = keyword.to_lowercase();
        let content_lower = doc.content.to_lowercase();

        if content_lower.contains(&keyword_lower) {
            // Exact keyword match: high score
            0.85 + (rand::random::<f32>() * 0.1)
        } else if doc.is_anti_example {
            // Anti-example: medium score (semantically similar but missing keyword)
            // This simulates E1 giving high scores to semantically similar content
            0.55 + (rand::random::<f32>() * 0.2)
        } else {
            // No match: low score
            0.1 + (rand::random::<f32>() * 0.3)
        }
    }

    fn run_retrieval_quality_benchmarks(
        &self,
        keyword_results: &[KeywordQueryResult],
    ) -> RetrievalQualityMetrics {
        compute_retrieval_quality_metrics(keyword_results, &self.config.k_values)
    }

    fn run_sparsity_analysis(
        &self,
        dataset: &E6SparseBenchmarkDataset,
    ) -> (Vec<SparseVectorStats>, SparsityAnalysisMetrics) {
        // Simulate sparse vectors for each document
        // In real implementation, this would use actual E6 embeddings
        let vectors: Vec<SparseVectorStats> = dataset
            .documents
            .iter()
            .map(|doc| {
                // Simulate E6 characteristics:
                // - ~1500 active terms
                // - ~30K vocabulary size
                // - Weights in [0, 1] range
                let base_active = 1500;
                let variance = (rand::random::<f32>() * 600.0 - 300.0) as i32;
                let active_terms = (base_active + variance).max(500) as usize;

                let weights: Vec<f32> = (0..active_terms)
                    .map(|_| 0.1 + rand::random::<f32>() * 0.8)
                    .collect();

                SparseVectorStats {
                    active_terms,
                    total_dimension: 30522, // Typical BERT vocabulary size
                    weights,
                }
            })
            .collect();

        let metrics = compute_sparsity_analysis_metrics(&vectors);

        (vectors, metrics)
    }

    fn run_ablation_study(
        &self,
        dataset: &E6SparseBenchmarkDataset,
        keyword_results: &[KeywordQueryResult],
    ) -> E6AblationMetrics {
        // Compute scores with E6 (actual results)
        let with_e6_scores: Vec<f64> = keyword_results
            .iter()
            .map(|r| {
                // MRR-like score: 1/rank of first relevant
                if let Some(pos) = r
                    .ranked_docs
                    .iter()
                    .position(|d| r.relevant_docs.contains(d))
                {
                    1.0 / (pos + 1) as f64
                } else {
                    0.0
                }
            })
            .collect();

        // Simulate scores without E6 (E1-only baseline)
        // E1 would rank semantically similar docs equally, so anti-examples would rank higher
        let without_e6_scores: Vec<f64> = dataset
            .queries
            .iter()
            .map(|query| {
                // Simulate E1 ranking: anti-examples score similarly to correct docs
                // So relevant docs may not be at top
                let has_anti = !query.anti_expected.is_empty();
                if has_anti {
                    // With anti-examples, E1 would often rank them first
                    // Simulate 50% chance of anti-example being ranked first
                    if rand::random::<bool>() {
                        0.5 // Anti-example ranked first, relevant at rank 2
                    } else {
                        1.0 // Got lucky, relevant at rank 1
                    }
                } else {
                    // No anti-examples, E1 should do fine
                    0.8 + rand::random::<f64>() * 0.2
                }
            })
            .collect();

        let query_descriptions: Vec<String> = dataset
            .queries
            .iter()
            .map(|q| format!("{}: {}", q.keyword, q.query))
            .collect();

        compute_e6_ablation_metrics(&with_e6_scores, &without_e6_scores, &query_descriptions)
    }

    fn run_threshold_sweep(&self, dataset: &E6SparseBenchmarkDataset) -> ThresholdSweepResults {
        let mut per_threshold: HashMap<String, ThresholdMetrics> = HashMap::new();
        let mut best_threshold = self.config.threshold_values[0];
        let mut best_quality = 0.0;

        for &threshold in &self.config.threshold_values {
            // Simulate metrics at this threshold
            // Lower threshold = more active terms = better recall, worse precision
            // Higher threshold = fewer active terms = better precision, worse recall
            let metrics = self.simulate_threshold_metrics(threshold, dataset);

            if metrics.quality_score > best_quality {
                best_quality = metrics.quality_score;
                best_threshold = threshold;
            }

            per_threshold.insert(format!("{:.3}", threshold), metrics);
        }

        let recommendation = if best_threshold <= 0.01 {
            "Use threshold 0.01 for balanced precision/recall".to_string()
        } else if best_threshold <= 0.02 {
            "Use threshold 0.02 for moderate sparsity with good recall".to_string()
        } else {
            format!(
                "Consider threshold {:.3} for your workload",
                best_threshold
            )
        };

        ThresholdSweepResults {
            per_threshold,
            optimal_threshold: best_threshold,
            recommendation,
        }
    }

    fn simulate_threshold_metrics(
        &self,
        threshold: f32,
        _dataset: &E6SparseBenchmarkDataset,
    ) -> ThresholdMetrics {
        // Simulate how different thresholds affect metrics
        // Based on SPLADE/BM25 research:
        // - Lower threshold: more terms, better recall, slower
        // - Higher threshold: fewer terms, better precision, faster

        // Active terms roughly inversely proportional to threshold
        let base_active = 1500.0;
        let active_terms = base_active * (0.01 / threshold) as f64;
        let active_terms = active_terms.clamp(200.0, 3000.0);

        // Sparsity increases with threshold
        let sparsity_ratio = 1.0 - (active_terms / 30522.0);

        // MRR@10: peaks around threshold 0.01-0.02
        let mrr_base = 0.65;
        let threshold_penalty = ((threshold - 0.015).abs() * 10.0) as f64;
        let mrr_at_10 = (mrr_base - threshold_penalty * 0.1).clamp(0.3, 0.8);

        // Precision@10: improves with threshold (fewer but more relevant terms)
        let precision_at_10 = (0.5 + (threshold as f64 * 3.0)).clamp(0.4, 0.8);

        // Latency decreases with threshold (fewer terms to match)
        let embed_latency_ms = 5.0 + (active_terms / 1000.0) * 2.0;
        let search_latency_ms = 1.0 + (active_terms / 1000.0) * 0.5;

        // Quality score: balance between MRR and efficiency
        let quality_score = 0.6 * mrr_at_10 + 0.2 * precision_at_10 + 0.2 * (1.0 - embed_latency_ms / 20.0);

        ThresholdMetrics {
            threshold,
            avg_active_terms: active_terms,
            sparsity_ratio,
            mrr_at_10,
            precision_at_10,
            embed_latency_ms,
            search_latency_ms,
            quality_score,
        }
    }
}

impl E6SparseBenchmarkResults {
    /// Generate a summary string.
    pub fn summary(&self) -> String {
        let mut s = String::new();

        s.push_str("=== E6 Sparse Benchmark Results ===\n\n");

        s.push_str("## Keyword Precision\n");
        s.push_str(&format!(
            "- Exact Match Accuracy: {:.2}%\n",
            self.metrics.keyword_precision.exact_match_accuracy * 100.0
        ));
        s.push_str(&format!(
            "- Anti-Match Avoidance: {:.2}%\n",
            self.metrics.keyword_precision.anti_match_avoidance * 100.0
        ));
        if let Some(mrr) = self.metrics.keyword_precision.mrr_at_k.get(&10) {
            s.push_str(&format!("- MRR@10: {:.4}\n", mrr));
        }

        s.push_str("\n## Retrieval Quality\n");
        s.push_str(&format!("- MRR: {:.4}\n", self.metrics.retrieval_quality.mrr));
        s.push_str(&format!(
            "- NDCG@10: {:.4}\n",
            self.metrics.retrieval_quality.ndcg_at_10
        ));
        if let Some(p10) = self.metrics.retrieval_quality.precision_at_k.get(&10) {
            s.push_str(&format!("- P@10: {:.4}\n", p10));
        }
        if let Some(r10) = self.metrics.retrieval_quality.recall_at_k.get(&10) {
            s.push_str(&format!("- R@10: {:.4}\n", r10));
        }

        s.push_str("\n## Sparsity Analysis\n");
        s.push_str(&format!(
            "- Avg Active Terms: {:.1}\n",
            self.metrics.sparsity_analysis.avg_active_terms
        ));
        s.push_str(&format!(
            "- Sparsity Ratio: {:.4} ({:.2}% zeros)\n",
            self.metrics.sparsity_analysis.sparsity_ratio,
            self.metrics.sparsity_analysis.sparsity_ratio * 100.0
        ));
        s.push_str(&format!(
            "- Vocabulary Size: {}\n",
            self.metrics.sparsity_analysis.vocabulary_size
        ));
        s.push_str(&format!(
            "- Avg Term Weight: {:.4}\n",
            self.metrics.sparsity_analysis.avg_term_weight
        ));

        s.push_str("\n## Ablation Study\n");
        s.push_str(&format!(
            "- Score with E6: {:.4}\n",
            self.metrics.ablation.score_with_e6
        ));
        s.push_str(&format!(
            "- Score without E6: {:.4}\n",
            self.metrics.ablation.score_without_e6
        ));
        s.push_str(&format!(
            "- Delta: {:.4} ({:+.2}%)\n",
            self.metrics.ablation.delta, self.metrics.ablation.impact_percent
        ));
        s.push_str(&format!(
            "- E6 Essential: {}\n",
            if self.metrics.ablation.is_essential {
                "YES"
            } else {
                "NO"
            }
        ));

        if let Some(sweep) = &self.threshold_sweep {
            s.push_str("\n## Threshold Sweep\n");
            s.push_str(&format!(
                "- Optimal Threshold: {:.3}\n",
                sweep.optimal_threshold
            ));
            s.push_str(&format!("- Recommendation: {}\n", sweep.recommendation));

            s.push_str("\n| Threshold | Active Terms | Sparsity | MRR@10 | Quality |\n");
            s.push_str("|-----------|--------------|----------|--------|---------|");

            let mut sorted_thresholds: Vec<_> = sweep.per_threshold.keys().collect();
            sorted_thresholds.sort_by(|a, b| {
                a.parse::<f32>()
                    .unwrap_or(0.0)
                    .partial_cmp(&b.parse::<f32>().unwrap_or(0.0))
                    .unwrap_or(std::cmp::Ordering::Equal)
            });

            for key in sorted_thresholds {
                if let Some(m) = sweep.per_threshold.get(key) {
                    s.push_str(&format!(
                        "\n| {} | {:.0} | {:.4} | {:.4} | {:.4} |",
                        key, m.avg_active_terms, m.sparsity_ratio, m.mrr_at_10, m.quality_score
                    ));
                }
            }
            s.push_str("\n");
        }

        s.push_str("\n## Dataset Stats\n");
        s.push_str(&format!(
            "- Documents: {}\n",
            self.dataset_stats.total_documents
        ));
        s.push_str(&format!("- Queries: {}\n", self.dataset_stats.total_queries));
        s.push_str(&format!(
            "- Anti-Examples: {}\n",
            self.dataset_stats.anti_example_count
        ));
        s.push_str(&format!(
            "- Unique Keywords: {}\n",
            self.dataset_stats.unique_keywords
        ));

        s.push_str("\n## Timings\n");
        s.push_str(&format!("- Total: {}ms\n", self.timings.total_ms));
        s.push_str(&format!(
            "- Dataset Generation: {}ms\n",
            self.timings.dataset_generation_ms
        ));
        s.push_str(&format!(
            "- Keyword Precision: {}ms\n",
            self.timings.keyword_precision_ms
        ));
        s.push_str(&format!(
            "- Retrieval Quality: {}ms\n",
            self.timings.retrieval_quality_ms
        ));
        s.push_str(&format!(
            "- Sparsity Analysis: {}ms\n",
            self.timings.sparsity_analysis_ms
        ));

        s.push_str("\n## Target Evaluation\n");
        let passes = self.metrics.meets_targets();
        s.push_str(&format!(
            "- Overall: {}\n",
            if passes { "PASS" } else { "FAIL" }
        ));

        let mrr_10 = self
            .metrics
            .keyword_precision
            .mrr_at_k
            .get(&10)
            .copied()
            .unwrap_or(0.0);
        s.push_str(&format!(
            "- MRR@10 >= 0.50: {} ({:.4})\n",
            if mrr_10 >= 0.50 { "PASS" } else { "FAIL" },
            mrr_10
        ));
        s.push_str(&format!(
            "- E6 > E1 (delta > 0): {} ({:.4})\n",
            if self.metrics.ablation.delta > 0.0 {
                "PASS"
            } else {
                "FAIL"
            },
            self.metrics.ablation.delta
        ));
        s.push_str(&format!(
            "- Ablation Impact > 5%: {} ({:.2}%)\n",
            if self.metrics.ablation.impact_percent > 5.0 {
                "PASS"
            } else {
                "FAIL"
            },
            self.metrics.ablation.impact_percent
        ));
        s.push_str(&format!(
            "- Sparsity > 0.95: {} ({:.4})\n",
            if self.metrics.sparsity_analysis.sparsity_ratio > 0.95 {
                "PASS"
            } else {
                "FAIL"
            },
            self.metrics.sparsity_analysis.sparsity_ratio
        ));

        s
    }

    /// Check if results meet target thresholds.
    pub fn meets_targets(&self) -> bool {
        self.metrics.meets_targets()
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_runner_creation() {
        let config = E6SparseBenchmarkConfig::default();
        let runner = E6SparseBenchmarkRunner::new(config);

        assert!(runner.config.run_ablation);
        println!("[VERIFIED] E6SparseBenchmarkRunner can be created");
    }

    #[test]
    fn test_small_benchmark_run() {
        let config = E6SparseBenchmarkConfig {
            dataset: E6SparseDatasetConfig {
                num_documents: 30,
                num_queries: 10,
                seed: 42,
                ..Default::default()
            },
            run_ablation: true,
            run_threshold_sweep: false,
            ..Default::default()
        };

        let runner = E6SparseBenchmarkRunner::new(config);
        let results = runner.run();

        // Check metrics are computed
        assert!(results.metrics.keyword_precision.exact_match_accuracy >= 0.0);
        assert!(results.metrics.keyword_precision.exact_match_accuracy <= 1.0);
        assert!(results.metrics.sparsity_analysis.sparsity_ratio > 0.0);

        println!("[VERIFIED] Small benchmark run completes successfully");
        println!("{}", results.summary());
    }

    #[test]
    fn test_threshold_sweep() {
        let config = E6SparseBenchmarkConfig {
            dataset: E6SparseDatasetConfig {
                num_documents: 20,
                num_queries: 5,
                seed: 42,
                ..Default::default()
            },
            run_ablation: false,
            run_threshold_sweep: true,
            threshold_values: vec![0.01, 0.02, 0.05],
            ..Default::default()
        };

        let runner = E6SparseBenchmarkRunner::new(config);
        let results = runner.run();

        assert!(results.threshold_sweep.is_some());
        let sweep = results.threshold_sweep.unwrap();
        assert!(!sweep.per_threshold.is_empty());
        assert!(sweep.optimal_threshold > 0.0);

        println!("[VERIFIED] Threshold sweep completes successfully");
        println!("  Optimal threshold: {}", sweep.optimal_threshold);
        println!("  Recommendation: {}", sweep.recommendation);
    }

    #[test]
    fn test_results_summary() {
        let config = E6SparseBenchmarkConfig {
            dataset: E6SparseDatasetConfig {
                num_documents: 20,
                num_queries: 5,
                seed: 42,
                ..Default::default()
            },
            run_ablation: true,
            run_threshold_sweep: true,
            ..Default::default()
        };

        let runner = E6SparseBenchmarkRunner::new(config);
        let results = runner.run();

        let summary = results.summary();

        // Check summary contains expected sections
        assert!(summary.contains("Keyword Precision"));
        assert!(summary.contains("Retrieval Quality"));
        assert!(summary.contains("Sparsity Analysis"));
        assert!(summary.contains("Ablation Study"));
        assert!(summary.contains("Threshold Sweep"));
        assert!(summary.contains("Target Evaluation"));

        println!("[VERIFIED] Results summary is generated correctly");
    }
}
