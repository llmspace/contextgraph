# M06-T02: Define EmbeddingProvider Trait & Factory in context-graph-core

```yaml
metadata:
  id: "M06-T02"
  title: "Define EmbeddingProvider Trait & Factory in context-graph-core"
  module: "module-06"
  module_name: "Stub Elimination"
  layer: "foundation"
  priority: "critical"
  estimated_hours: 4
  created: "2026-01-04"
  updated: "2026-01-04"
  status: "ready"
  dependencies: []
  blocks: ["M06-T04", "M06-T10"]
  spec_refs:
    - "docs2/constitution.yaml:305-323"   # 12-model embedding pipeline
    - "docs2/constitution.yaml:108-122"   # Performance budgets: single_embed <10ms, batch_embed_64 <50ms
    - "docs2/contextprd.md:189-208"       # Embedding models E1-E12
```

## Problem Statement

The MCP handlers use hardcoded fake embeddings `vec![0.1; 1536]` instead of real embedding generation. The `context-graph-embeddings` crate has a real `EmbeddingProvider` trait but:

1. It's defined in `context-graph-embeddings`, creating a circular dependency if MCP imports it directly
2. The `context-graph-core` crate (which MCP depends on) has NO embedding provider trait
3. MCP handlers cannot inject real embedding providers without a trait in core

### Current State (VERIFIED 2026-01-04)

**Fake Embeddings in MCP** - `crates/context-graph-mcp/src/handlers/tools.rs`:
```rust
// Line 230 - inject_context
let embedding = vec![0.1; 1536]; // FAKE: All content gets identical embeddings

// Line 273 - store_memory
let embedding = vec![0.1; 1536]; // FAKE: Meaningless for similarity search
```

**Real Trait in Embeddings Crate** - `crates/context-graph-embeddings/src/provider.rs`:
```rust
#[async_trait]
pub trait EmbeddingProvider: Send + Sync {
    async fn embed(&self, text: &str) -> EmbeddingResult<Vec<f32>>;
    async fn embed_batch(&self, texts: &[&str]) -> EmbeddingResult<Vec<Vec<f32>>>;
    fn dimension(&self) -> usize;
    fn model_name(&self) -> &str;
    fn max_tokens(&self) -> usize;
}
```

**No Trait in Core** - `crates/context-graph-core/src/traits/mod.rs`:
```rust
// Current exports (NO EmbeddingProvider):
pub use graph_index::GraphIndex;
pub use memory_store::{MemoryStore, SearchOptions};
pub use nervous_layer::NervousLayer;
pub use utl_processor::UtlProcessor;
```

## Solution

Create an `EmbeddingProvider` trait in `context-graph-core` that:
1. Mirrors the interface from `context-graph-embeddings` for compatibility
2. Uses `CoreResult` error type for consistency with other core traits
3. Adds `EmbeddingResult` struct with metadata (model_id, dimensions, latency)
4. Enables injection of real providers via M06-T04

## Input Context Files (READ BEFORE IMPLEMENTING)

| File | Purpose |
|------|---------|
| `crates/context-graph-embeddings/src/provider.rs` | Reference trait design |
| `crates/context-graph-core/src/traits/mod.rs` | Add new module export |
| `crates/context-graph-core/src/traits/utl_processor.rs` | Reference for async trait pattern |
| `crates/context-graph-core/src/error.rs` | CoreError for error variants |
| `crates/context-graph-mcp/src/handlers/tools.rs` | Consumer of embeddings (lines 230, 273) |

## Definition of Done

### 1. Create Trait Definition

**File: `crates/context-graph-core/src/traits/embedding_provider.rs`**

```rust
//! Embedding provider trait for text-to-vector conversion.
//!
//! This trait defines the interface for embedding generation that MCP handlers
//! use. Implementations include:
//! - `StubEmbeddingProvider`: Deterministic test embeddings (hash-based)
//! - Real Candle-based provider (M06-T04)
//!
//! # Performance Requirements (constitution.yaml:108-122)
//! - Single embed: <10ms
//! - Batch embed (64): <50ms
//!
//! # FAIL FAST: No fallbacks. Errors propagate immediately.

use async_trait::async_trait;
use crate::error::CoreResult;
use serde::{Deserialize, Serialize};
use std::time::Duration;

/// Result of embedding generation with metadata.
///
/// Contains the embedding vector plus diagnostic information
/// for performance monitoring and debugging.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct EmbeddingOutput {
    /// The embedding vector (1536 dimensions by default).
    pub vector: Vec<f32>,
    /// Model identifier that generated this embedding.
    pub model_id: String,
    /// Actual vector dimensions.
    pub dimensions: usize,
    /// Time taken to generate embedding.
    pub latency: Duration,
}

impl EmbeddingOutput {
    /// Create new embedding output with validation.
    ///
    /// # Errors
    /// Returns error if vector is empty or dimensions mismatch.
    pub fn new(
        vector: Vec<f32>,
        model_id: impl Into<String>,
        latency: Duration,
    ) -> CoreResult<Self> {
        if vector.is_empty() {
            return Err(crate::error::CoreError::Embedding(
                "Empty embedding vector".into(),
            ));
        }
        let dimensions = vector.len();
        Ok(Self {
            vector,
            model_id: model_id.into(),
            dimensions,
            latency,
        })
    }
}

/// Trait for embedding generation.
///
/// Provides async interface for converting text to dense vector representations.
/// All implementations must be thread-safe (Send + Sync) for use in async handlers.
///
/// # Error Handling
///
/// FAIL FAST: Errors propagate immediately. No fallbacks to fake embeddings.
/// If embedding generation fails, the caller receives the error.
///
/// # Example
///
/// ```rust,ignore
/// let embedding = provider.embed("Some text content").await?;
/// assert_eq!(embedding.dimensions, 1536);
/// ```
#[async_trait]
pub trait EmbeddingProvider: Send + Sync {
    /// Generate embedding for single text content.
    ///
    /// # Arguments
    /// * `content` - Text to embed (max 8192 tokens typical)
    ///
    /// # Returns
    /// `EmbeddingOutput` with vector and metadata on success.
    ///
    /// # Errors
    /// - `CoreError::Embedding` if generation fails
    /// - `CoreError::Timeout` if exceeds 10ms budget
    ///
    /// # Performance
    /// Target: <10ms (constitution.yaml:115)
    async fn embed(&self, content: &str) -> CoreResult<EmbeddingOutput>;

    /// Generate embeddings for batch of texts.
    ///
    /// More efficient than calling `embed` in a loop.
    /// Implementations should process in parallel where possible.
    ///
    /// # Arguments
    /// * `contents` - Slice of texts to embed
    ///
    /// # Returns
    /// Vector of `EmbeddingOutput` in same order as input.
    ///
    /// # Errors
    /// - `CoreError::Embedding` if any generation fails
    /// - `CoreError::Timeout` if exceeds 50ms budget for 64 items
    ///
    /// # Performance
    /// Target: <50ms for 64 items (constitution.yaml:116)
    async fn embed_batch(&self, contents: &[String]) -> CoreResult<Vec<EmbeddingOutput>>;

    /// Get the output dimension for embeddings.
    ///
    /// Default is 1536 (OpenAI ada-002 compatible, FuseMoE output).
    fn dimensions(&self) -> usize;

    /// Get the model identifier string.
    ///
    /// Used for logging, debugging, and `EmbeddingOutput.model_id`.
    fn model_id(&self) -> &str;

    /// Check if provider is ready to generate embeddings.
    ///
    /// Returns false if model needs initialization (weight loading, GPU warm-up).
    fn is_ready(&self) -> bool;
}
```

### 2. Create Stub Implementation

**File: `crates/context-graph-core/src/stubs/embedding_stub.rs`**

```rust
//! Stub embedding provider for testing.
//!
//! Generates DETERMINISTIC embeddings based on content hash.
//! NOT for production - use real Candle provider (M06-T04).
//!
//! # How It Works
//!
//! 1. Hash content using xxhash64
//! 2. Seed RNG with hash
//! 3. Generate deterministic vector from seeded RNG
//! 4. Normalize to unit length
//!
//! This ensures:
//! - Same content â†’ same embedding (deterministic tests)
//! - Different content â†’ different embedding (similarity works)
//! - Embeddings are normalized (cosine similarity valid)
//!
//! # NEVER use vec![0.1; 1536] - all nodes would be identical!

use crate::error::{CoreError, CoreResult};
use crate::traits::{EmbeddingOutput, EmbeddingProvider};
use async_trait::async_trait;
use std::time::{Duration, Instant};

/// Stub embedding provider for testing.
///
/// Generates hash-based deterministic embeddings.
/// Different content produces different (but repeatable) vectors.
pub struct StubEmbeddingProvider {
    dimensions: usize,
    model_id: String,
}

impl Default for StubEmbeddingProvider {
    fn default() -> Self {
        Self::new()
    }
}

impl StubEmbeddingProvider {
    /// Create with default 1536 dimensions.
    pub fn new() -> Self {
        Self {
            dimensions: 1536,
            model_id: "stub-embedding-v1".to_string(),
        }
    }

    /// Create with custom dimensions.
    pub fn with_dimensions(dimensions: usize) -> Self {
        Self {
            dimensions,
            model_id: format!("stub-embedding-v1-d{}", dimensions),
        }
    }

    /// Generate deterministic embedding from content hash.
    ///
    /// Uses xxhash for fast hashing, seeds PRNG, generates normalized vector.
    fn generate_embedding(&self, content: &str) -> Vec<f32> {
        use std::collections::hash_map::DefaultHasher;
        use std::hash::{Hash, Hasher};

        // Hash content
        let mut hasher = DefaultHasher::new();
        content.hash(&mut hasher);
        let hash = hasher.finish();

        // Seed simple LCG PRNG
        let mut seed = hash;
        let mut vector = Vec::with_capacity(self.dimensions);

        for _ in 0..self.dimensions {
            // LCG: next = (a * seed + c) mod m
            seed = seed.wrapping_mul(6364136223846793005).wrapping_add(1);
            // Convert to f32 in [-1, 1]
            let value = (seed as f64 / u64::MAX as f64) * 2.0 - 1.0;
            vector.push(value as f32);
        }

        // Normalize to unit length
        let magnitude: f32 = vector.iter().map(|v| v * v).sum::<f32>().sqrt();
        if magnitude > 0.0 {
            for v in &mut vector {
                *v /= magnitude;
            }
        }

        vector
    }
}

#[async_trait]
impl EmbeddingProvider for StubEmbeddingProvider {
    async fn embed(&self, content: &str) -> CoreResult<EmbeddingOutput> {
        let start = Instant::now();

        if content.is_empty() {
            return Err(CoreError::Embedding("Empty content".into()));
        }

        let vector = self.generate_embedding(content);
        let latency = start.elapsed();

        EmbeddingOutput::new(vector, &self.model_id, latency)
    }

    async fn embed_batch(&self, contents: &[String]) -> CoreResult<Vec<EmbeddingOutput>> {
        let mut results = Vec::with_capacity(contents.len());
        for content in contents {
            results.push(self.embed(content).await?);
        }
        Ok(results)
    }

    fn dimensions(&self) -> usize {
        self.dimensions
    }

    fn model_id(&self) -> &str {
        &self.model_id
    }

    fn is_ready(&self) -> bool {
        true // Stub is always ready
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_stub_produces_correct_dimensions() {
        let provider = StubEmbeddingProvider::new();
        let result = provider.embed("test content").await.unwrap();
        assert_eq!(result.dimensions, 1536);
        assert_eq!(result.vector.len(), 1536);
    }

    #[tokio::test]
    async fn test_stub_different_content_different_embedding() {
        let provider = StubEmbeddingProvider::new();

        let emb1 = provider.embed("first content").await.unwrap();
        let emb2 = provider.embed("second content").await.unwrap();

        // Vectors must be different
        assert_ne!(emb1.vector, emb2.vector);

        // Cosine similarity should not be 1.0
        let dot: f32 = emb1.vector.iter().zip(&emb2.vector).map(|(a, b)| a * b).sum();
        assert!(dot < 0.99, "Different content should have different embeddings, got dot={}", dot);
    }

    #[tokio::test]
    async fn test_stub_same_content_same_embedding() {
        let provider = StubEmbeddingProvider::new();

        let emb1 = provider.embed("same content").await.unwrap();
        let emb2 = provider.embed("same content").await.unwrap();

        // Vectors must be identical (deterministic)
        assert_eq!(emb1.vector, emb2.vector);
    }

    #[tokio::test]
    async fn test_stub_embedding_normalized() {
        let provider = StubEmbeddingProvider::new();
        let result = provider.embed("test content").await.unwrap();

        let magnitude: f32 = result.vector.iter().map(|v| v * v).sum::<f32>().sqrt();
        assert!(
            (magnitude - 1.0).abs() < 0.001,
            "Embedding should be normalized, magnitude={}",
            magnitude
        );
    }

    #[tokio::test]
    async fn test_stub_empty_content_fails() {
        let provider = StubEmbeddingProvider::new();
        let result = provider.embed("").await;
        assert!(result.is_err());
    }

    #[tokio::test]
    async fn test_stub_batch_embedding() {
        let provider = StubEmbeddingProvider::new();
        let contents = vec![
            "first".to_string(),
            "second".to_string(),
            "third".to_string(),
        ];

        let results = provider.embed_batch(&contents).await.unwrap();
        assert_eq!(results.len(), 3);

        // All different
        assert_ne!(results[0].vector, results[1].vector);
        assert_ne!(results[1].vector, results[2].vector);
    }

    #[tokio::test]
    async fn test_stub_custom_dimensions() {
        let provider = StubEmbeddingProvider::with_dimensions(768);
        let result = provider.embed("test").await.unwrap();
        assert_eq!(result.dimensions, 768);
        assert_eq!(result.vector.len(), 768);
    }

    #[tokio::test]
    async fn test_stub_is_ready() {
        let provider = StubEmbeddingProvider::new();
        assert!(provider.is_ready());
    }

    #[tokio::test]
    async fn test_stub_latency_tracked() {
        let provider = StubEmbeddingProvider::new();
        let result = provider.embed("test content").await.unwrap();
        // Latency should be non-zero (even if tiny)
        assert!(result.latency.as_nanos() > 0);
    }
}
```

### 3. Update Module Exports

**File: `crates/context-graph-core/src/traits/mod.rs`** - Add:
```rust
mod embedding_provider;
pub use embedding_provider::{EmbeddingOutput, EmbeddingProvider};
```

**File: `crates/context-graph-core/src/stubs/mod.rs`** - Add:
```rust
mod embedding_stub;
pub use embedding_stub::StubEmbeddingProvider;
```

**File: `crates/context-graph-core/src/lib.rs`** - Verify exports:
```rust
// Should already export traits and stubs modules
pub use traits::{EmbeddingOutput, EmbeddingProvider, /* ... */};
pub use stubs::StubEmbeddingProvider;
```

### 4. Update CoreError

**File: `crates/context-graph-core/src/error.rs`** - Add variant if missing:
```rust
#[derive(Debug, thiserror::Error)]
pub enum CoreError {
    // ... existing variants ...

    /// Embedding generation failed.
    #[error("Embedding error: {0}")]
    Embedding(String),
}
```

## Constraints (ABSOLUTE)

1. **NO BACKWARDS COMPATIBILITY** - Old patterns using `vec![0.1; 1536]` must be removed, not wrapped
2. **NO MOCK DATA IN TESTS** - Tests use `StubEmbeddingProvider` which generates deterministic hash-based embeddings
3. **FAIL FAST** - Empty content returns error, never silent default
4. **Trait in core ONLY** - Do not modify `context-graph-embeddings` trait
5. **async trait required** - GPU operations are async, trait must be async

## Verification Commands

```bash
# 1. Build core crate
cargo build -p context-graph-core

# 2. Run trait tests
cargo test -p context-graph-core embedding -- --nocapture

# 3. Verify trait exports
grep -n "pub use embedding_provider" crates/context-graph-core/src/traits/mod.rs

# 4. Verify stub exports
grep -n "pub use embedding_stub" crates/context-graph-core/src/stubs/mod.rs

# 5. Verify no hardcoded vectors in stub
grep -c "vec!\[0\.1" crates/context-graph-core/src/stubs/embedding_stub.rs
# Expected: 0

# 6. Verify stub tests pass
cargo test -p context-graph-core test_stub_different_content_different_embedding -- --nocapture
```

## Full State Verification Protocol

After completing implementation, perform these verification steps:

### 1. Source of Truth Identification

The source of truth is the **StubEmbeddingProvider output**:
- `dimensions()` â†’ `EmbeddingOutput.dimensions`
- `model_id()` â†’ `EmbeddingOutput.model_id`
- Content hash â†’ deterministic vector values

### 2. Execute & Inspect Protocol

Run this test to verify behavior:

```rust
#[tokio::test]
async fn verify_source_of_truth() {
    let provider = StubEmbeddingProvider::new();

    // BEFORE: Check provider state
    println!("=== PROVIDER STATE ===");
    println!("dimensions: {}", provider.dimensions());
    println!("model_id: {}", provider.model_id());
    println!("is_ready: {}", provider.is_ready());

    // EXECUTE: Generate embedding
    let result = provider.embed("verification content").await.unwrap();

    // AFTER: Verify output matches source of truth
    println!("\n=== EMBEDDING OUTPUT ===");
    println!("vector length: {}", result.vector.len());
    println!("dimensions: {}", result.dimensions);
    println!("model_id: {}", result.model_id);
    println!("latency: {:?}", result.latency);
    println!("first 5 values: {:?}", &result.vector[..5]);

    // VERIFY: Consistency
    assert_eq!(result.dimensions, provider.dimensions());
    assert_eq!(result.model_id, provider.model_id());
    assert_eq!(result.vector.len(), result.dimensions);

    println!("\nâœ“ Source of truth verified");
}
```

### 3. Boundary & Edge Case Audit

Test these 3 edge cases with before/after state:

| Edge Case | Input | Expected Behavior |
|-----------|-------|-------------------|
| Empty content | `""` | `Err(CoreError::Embedding("Empty content"))` |
| Very long content | 100KB string | Success with valid embedding |
| Unicode content | `"æ—¥æœ¬èªžãƒ†ã‚¹ãƒˆðŸš€"` | Success with different embedding than ASCII |

```rust
#[tokio::test]
async fn edge_case_audit() {
    let provider = StubEmbeddingProvider::new();

    // EDGE CASE 1: Empty content
    println!("=== EDGE CASE 1: Empty Content ===");
    println!("BEFORE: provider ready = {}", provider.is_ready());
    let result = provider.embed("").await;
    println!("RESULT: {:?}", result);
    assert!(result.is_err());
    println!("AFTER: provider ready = {} (unchanged)", provider.is_ready());

    // EDGE CASE 2: Very long content
    println!("\n=== EDGE CASE 2: Long Content ===");
    let long_content = "x".repeat(100_000);
    println!("BEFORE: content length = {}", long_content.len());
    let result = provider.embed(&long_content).await;
    println!("RESULT: success = {}", result.is_ok());
    assert!(result.is_ok());
    println!("AFTER: dimensions = {}", result.unwrap().dimensions);

    // EDGE CASE 3: Unicode content
    println!("\n=== EDGE CASE 3: Unicode Content ===");
    let unicode = "æ—¥æœ¬èªžãƒ†ã‚¹ãƒˆðŸš€";
    let ascii = "Japanese Test";
    let emb_unicode = provider.embed(unicode).await.unwrap();
    let emb_ascii = provider.embed(ascii).await.unwrap();
    println!("Unicode embedding first 3: {:?}", &emb_unicode.vector[..3]);
    println!("ASCII embedding first 3: {:?}", &emb_ascii.vector[..3]);
    assert_ne!(emb_unicode.vector, emb_ascii.vector);
    println!("VERIFIED: Unicode produces different embedding than ASCII");
}
```

### 4. Evidence of Success

Final verification output must show:

```
=== EMBEDDING PROVIDER VERIFICATION REPORT ===
âœ“ Trait compiles (EmbeddingProvider in context-graph-core)
âœ“ Stub implementation compiles (StubEmbeddingProvider)
âœ“ All 5 trait methods implemented
âœ“ EmbeddingOutput contains vector + metadata
âœ“ Different content â†’ different embeddings (NOT vec![0.1; 1536])
âœ“ Same content â†’ same embedding (deterministic)
âœ“ Embeddings normalized (magnitude â‰ˆ 1.0)
âœ“ Empty content returns error (not silent default)
âœ“ Batch embedding works correctly

Sample output:
{
  "model_id": "stub-embedding-v1",
  "dimensions": 1536,
  "latency_ms": 0.05,
  "vector_sample": [0.023, -0.089, 0.156, ...]
}

All values above are COMPUTED from content hash, not hardcoded.
```

## Manual Output Verification Checklist

Before marking complete:

- [ ] `cargo build -p context-graph-core` succeeds
- [ ] `cargo test -p context-graph-core embedding` passes (all 9+ tests)
- [ ] `grep -c "vec!\[0\.1" crates/context-graph-core/src/stubs/embedding_stub.rs` returns 0
- [ ] Different content produces different embeddings
- [ ] Same content produces identical embeddings
- [ ] Embeddings are normalized (magnitude â‰ˆ 1.0)
- [ ] `EmbeddingOutput` includes latency tracking
- [ ] Empty content returns error

## Final Verification: Sherlock-Holmes Agent

**MANDATORY**: After completing implementation and tests, spawn `sherlock-holmes` subagent:

```
Task: Forensic investigation of M06-T02 implementation
- Verify EmbeddingProvider trait exists in context-graph-core/src/traits/
- Verify StubEmbeddingProvider exists in context-graph-core/src/stubs/
- Verify NO usage of vec![0.1; 1536] in stub
- Verify trait methods match specification
- Verify all tests use real stub (no mocks)
- Verify exports in mod.rs files
- Report any discrepancies between spec and implementation
```

Task is NOT complete until sherlock-holmes confirms all verification passes.

---

*Task created: 2026-01-04*
*Last updated: 2026-01-04*
*Module: 06 - Stub Elimination*
*Layer: Foundation*
*Priority: CRITICAL*
