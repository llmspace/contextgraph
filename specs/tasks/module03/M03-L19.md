<?xml version="1.0" encoding="UTF-8"?>
<task_spec id="M03-L19" version="1.0">
<metadata>
  <title>CacheManager Implementation with LRU Eviction</title>
  <status>ready</status>
  <layer>logic</layer>
  <sequence>19</sequence>
  <implements>PRD-EMB-003: Embedding Cache System</implements>
  <depends_on>M03-L18, M03-F15</depends_on>
  <estimated_hours>4</estimated_hours>
</metadata>

<context>
Implement embedding cache manager with LRU eviction and optional disk persistence.
The CacheManager stores FusedEmbeddings keyed by content hash, supporting fast
lookups (<100us target) and configurable eviction policies. The cache is critical
for achieving >80% hit rate on repeated content, reducing embedding computation
costs significantly.

Supports multiple eviction policies (LRU, LFU, TTL-LRU, ARC) and optional
persistence to disk for warm cache restoration across restarts.
</context>

<definition_of_done>
  <signatures>
```rust
pub struct CacheManager {
    entries: RwLock<LinkedHashMap<CacheKey, CacheEntry>>,
    config: CacheConfig,
    metrics: CacheMetrics,
}

pub struct CacheMetrics {
    pub hits: AtomicU64,
    pub misses: AtomicU64,
    pub evictions: AtomicU64,
    pub bytes_used: AtomicUsize,
}

impl CacheManager {
    pub fn new(config: CacheConfig) -> Self;

    pub fn get(&self, key: &CacheKey) -> Option<FusedEmbedding>;

    pub fn put(&self, key: CacheKey, embedding: FusedEmbedding);

    pub fn contains(&self, key: &CacheKey) -> bool;

    pub fn remove(&self, key: &CacheKey) -> Option<FusedEmbedding>;

    pub fn clear(&self);

    pub fn len(&self) -> usize;

    pub fn is_empty(&self) -> bool;

    pub fn hit_rate(&self) -> f32;

    pub fn memory_usage(&self) -> usize;

    pub async fn persist(&self) -> EmbeddingResult<()>;

    pub async fn load(&self) -> EmbeddingResult<()>;
}
```
  </signatures>

  <constraints>
    <constraint>Cache lookup latency: <100us</constraint>
    <constraint>LRU eviction when max_entries exceeded</constraint>
    <constraint>Memory-based eviction when max_bytes exceeded</constraint>
    <constraint>TTL-based expiration if ttl_seconds configured</constraint>
    <constraint>Hit rate target: >80% under normal workload</constraint>
    <constraint>Thread-safe via RwLock (read-heavy workload optimized)</constraint>
    <constraint>LinkedHashMap maintains insertion order for LRU</constraint>
    <constraint>Disk persistence uses bincode serialization</constraint>
  </constraints>
</definition_of_done>

<files_to_create>
  <file>crates/context-graph-embeddings/src/cache/manager.rs</file>
</files_to_create>

<validation_criteria>
  <criterion>cargo check passes</criterion>
  <criterion>cargo clippy passes without warnings</criterion>
  <criterion>Unit test: put/get round-trip works correctly</criterion>
  <criterion>Unit test: LRU eviction removes oldest entry</criterion>
  <criterion>Unit test: max_entries limit enforced</criterion>
  <criterion>Unit test: max_bytes limit enforced</criterion>
  <criterion>Unit test: TTL expiration works correctly</criterion>
  <criterion>Unit test: hit_rate calculation accurate</criterion>
  <criterion>Integration test: persist/load round-trip preserves entries</criterion>
  <criterion>Benchmark: get() latency <100us</criterion>
</validation_criteria>

<implementation_notes>
LinkedHashMap from linked-hash-map crate provides O(1) operations with LRU semantics:
- get() moves entry to end (most recently used)
- Eviction removes from front (least recently used)

For ARC (Adaptive Replacement Cache) policy:
- Track both recency and frequency
- Dynamically balance between LRU and LFU

Disk persistence format:
- Header: version, entry count, checksum
- Entries: bincode-serialized (key, embedding) pairs
- Footer: integrity checksum
</implementation_notes>
</task_spec>
