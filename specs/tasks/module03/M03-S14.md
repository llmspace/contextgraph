# Task Specification: M03-S14

```xml
<task_spec id="M03-S14" version="1.0">
<metadata>
  <title>Green Context SM Partitioning</title>
  <status>ready</status>
  <layer>surface</layer>
  <sequence>49</sequence>
  <implements>
    - RTX 5090 Technical Report: Green Contexts for SM isolation
    - Technical Engine Section 3.2: Quad Partition (170 SMs per context)
    - Constitution: hardware.gpu_partitioning
  </implements>
  <depends_on>
    - M03-S04 (CUDA Device Trait)
    - M03-S05 (GPU Memory Pool)
  </depends_on>
  <estimated_hours>6</estimated_hours>
</metadata>

<context>
Implement Green Context SM Partitioning for RTX 5090 to ensure the embedding pipeline
has dedicated compute resources that cannot be starved by background "Dream" processes
or other GPU workloads.

The RTX 5090 has 680 SMs (Streaming Multiprocessors). Using CUDA 13.1 Green Contexts,
we can partition these into isolated execution contexts. The Technical Engine specifies
a "Quad Partition" strategy:
- Context 0: Embedding Pipeline (170 SMs) - HIGH priority
- Context 1: Dream/Background (170 SMs) - LOW priority
- Context 2: Training (170 SMs) - MEDIUM priority
- Context 3: Reserved/Overflow (170 SMs) - MEDIUM priority

This ensures embedding latency remains predictable even during heavy background activity.
</context>

<definition_of_done>
  <signatures>
```rust
/// Green Context configuration
#[derive(Debug, Clone)]
pub struct GreenContextConfig {
    /// Number of SMs to allocate to this context
    pub sm_count: u32,
    /// Priority level
    pub priority: ContextPriority,
    /// Memory limit for this context
    pub memory_limit_bytes: u64,
    /// Whether to enable preemption
    pub preemptible: bool,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum ContextPriority {
    Critical,  // Never preempted
    High,      // Rarely preempted
    Medium,    // Normal scheduling
    Low,       // Preempted when needed
}

/// Represents an isolated CUDA execution context
pub struct GreenContext {
    handle: CUcontext,
    config: GreenContextConfig,
    allocated_sms: u32,
    device_id: i32,
}

/// Manages partitioning of GPU SMs across contexts
pub struct SmPartitionManager {
    device_info: DeviceInfo,
    contexts: HashMap<ContextId, GreenContext>,
    total_sms: u32,
    allocated_sms: u32,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
pub enum ContextId {
    Embedding,
    Dream,
    Training,
    Reserved,
}

impl SmPartitionManager {
    /// Create manager for specified GPU device
    pub fn new(device_id: i32) -> EmbeddingResult<Self>;

    /// Initialize quad partition for RTX 5090
    pub fn init_quad_partition(&mut self) -> EmbeddingResult<()>;

    /// Create a new Green Context with specified SM count
    pub fn create_context(
        &mut self,
        id: ContextId,
        config: GreenContextConfig,
    ) -> EmbeddingResult<&GreenContext>;

    /// Get context by ID
    pub fn get_context(&self, id: ContextId) -> Option<&GreenContext>;

    /// Set current context for execution
    pub fn set_current(&self, id: ContextId) -> EmbeddingResult<()>;

    /// Get current SM allocation status
    pub fn allocation_status(&self) -> AllocationStatus;

    /// Destroy context and release SMs
    pub fn destroy_context(&mut self, id: ContextId) -> EmbeddingResult<()>;

    /// Rebalance SM allocation based on workload
    pub fn rebalance(&mut self, hint: RebalanceHint) -> EmbeddingResult<()>;
}

/// SM allocation status
#[derive(Debug, Clone)]
pub struct AllocationStatus {
    pub total_sms: u32,
    pub allocated_sms: u32,
    pub available_sms: u32,
    pub contexts: Vec<(ContextId, u32)>,
}

/// Hint for rebalancing
#[derive(Debug, Clone)]
pub enum RebalanceHint {
    EmbeddingHeavy,   // Give more SMs to embedding
    TrainingActive,   // Balance embedding/training
    DreamActive,      // Allow dream to use more
    Balanced,         // Even distribution
}

/// Guard that ensures context is active for duration
pub struct ContextGuard<'a> {
    manager: &'a SmPartitionManager,
    previous_context: ContextId,
}

impl SmPartitionManager {
    /// Activate context and return guard that restores previous on drop
    pub fn activate(&self, id: ContextId) -> EmbeddingResult<ContextGuard<'_>>;
}
```
  </signatures>

  <constraints>
    - Requires CUDA 13.1+ for Green Context support
    - RTX 5090 specific: 680 SMs, Quad Partition = 170 each
    - Fallback for older GPUs: single context mode
    - SM count must not exceed device total
    - Context creation may fail if insufficient SMs available
    - Priority enforcement via CUDA scheduler hints
    - Memory limits enforced per-context
    - Thread-safe: contexts can be activated from different threads
    - Guard pattern: automatic context restoration
  </constraints>

  <verification>
    <step>init_quad_partition creates 4 contexts with 170 SMs each</step>
    <step>Embedding context has Critical priority</step>
    <step>set_current switches active context</step>
    <step>ContextGuard restores previous context on drop</step>
    <step>Fallback mode works on non-RTX-5090 GPUs</step>
    <step>rebalance adjusts SM counts without destroying contexts</step>
    <step>Memory limits enforced per context</step>
  </verification>
</definition_of_done>

<files_to_create>
  <file>crates/context-graph-embeddings/src/cuda/green_context.rs</file>
  <file>crates/context-graph-embeddings/src/cuda/sm_partition.rs</file>
  <file>crates/context-graph-embeddings/src/cuda/context_guard.rs</file>
</files_to_create>

<validation_criteria>
  <criterion>cargo check passes (with cuda feature)</criterion>
  <criterion>CUDA 13.1 API bindings compile correctly</criterion>
  <criterion>Quad partition test on RTX 5090 (integration test)</criterion>
  <criterion>Fallback mode works on older hardware</criterion>
  <criterion>No SM overallocation possible</criterion>
</validation_criteria>
</task_spec>
```

## Implementation Notes

### CUDA 13.1 Green Context API

```rust
// Bindings to CUDA 13.1 Green Context API (cugreen*)
extern "C" {
    fn cuGreenCtxCreate(
        ctx: *mut CUcontext,
        sm_count: u32,
        flags: u32,
    ) -> CUresult;

    fn cuGreenCtxGetSMCount(
        ctx: CUcontext,
        sm_count: *mut u32,
    ) -> CUresult;

    fn cuGreenCtxSetPriority(
        ctx: CUcontext,
        priority: i32,
    ) -> CUresult;
}

impl GreenContext {
    pub fn new(config: GreenContextConfig, device_id: i32) -> EmbeddingResult<Self> {
        unsafe {
            let mut handle: CUcontext = std::ptr::null_mut();

            let flags = match config.priority {
                ContextPriority::Critical => CUDA_CTX_SCHED_SPIN,
                ContextPriority::High => CUDA_CTX_SCHED_YIELD,
                _ => CUDA_CTX_SCHED_AUTO,
            };

            let result = cuGreenCtxCreate(&mut handle, config.sm_count, flags);
            if result != CUDA_SUCCESS {
                return Err(EmbeddingError::CudaError(result));
            }

            Ok(Self {
                handle,
                config,
                allocated_sms: config.sm_count,
                device_id,
            })
        }
    }
}
```

### Quad Partition Initialization

```rust
impl SmPartitionManager {
    pub fn init_quad_partition(&mut self) -> EmbeddingResult<()> {
        // RTX 5090: 680 SMs / 4 = 170 per context
        let sms_per_context = self.total_sms / 4;

        // Embedding: Critical priority, non-preemptible
        self.create_context(ContextId::Embedding, GreenContextConfig {
            sm_count: sms_per_context,
            priority: ContextPriority::Critical,
            memory_limit_bytes: 8 * 1024 * 1024 * 1024, // 8GB
            preemptible: false,
        })?;

        // Dream: Low priority, preemptible
        self.create_context(ContextId::Dream, GreenContextConfig {
            sm_count: sms_per_context,
            priority: ContextPriority::Low,
            memory_limit_bytes: 8 * 1024 * 1024 * 1024,
            preemptible: true,
        })?;

        // Training: Medium priority
        self.create_context(ContextId::Training, GreenContextConfig {
            sm_count: sms_per_context,
            priority: ContextPriority::Medium,
            memory_limit_bytes: 8 * 1024 * 1024 * 1024,
            preemptible: true,
        })?;

        // Reserved: Medium priority, overflow
        self.create_context(ContextId::Reserved, GreenContextConfig {
            sm_count: sms_per_context,
            priority: ContextPriority::Medium,
            memory_limit_bytes: 8 * 1024 * 1024 * 1024,
            preemptible: true,
        })?;

        Ok(())
    }
}
```

### Integration with Embedding Pipeline

```rust
impl EmbeddingPipeline {
    pub async fn embed(&self, content: &str) -> EmbeddingResult<FusedEmbedding> {
        // Activate embedding context for this operation
        let _guard = self.sm_manager.activate(ContextId::Embedding)?;

        // All CUDA operations now use the 170 dedicated SMs
        let scrubbed = self.pii_scrubber.scrub(content);
        let cache_key = self.hash_content(&scrubbed.cleaned);

        if let Some(cached) = self.cache.get(&cache_key).await? {
            return Ok(cached);
        }

        // Batch processing uses dedicated SMs
        let embeddings = self.batch_processor.process(&scrubbed.cleaned).await?;
        let fused = self.fusemoe.fuse(&embeddings).await?;

        self.cache.put(&cache_key, &fused).await?;
        Ok(fused)
        // _guard drops here, restoring previous context
    }
}
```

### Fallback for Non-RTX-5090

```rust
impl SmPartitionManager {
    pub fn new(device_id: i32) -> EmbeddingResult<Self> {
        let device_info = get_device_info(device_id)?;

        // Check for Green Context support
        if !device_info.supports_green_contexts() {
            log::warn!(
                "GPU {} does not support Green Contexts, using single context mode",
                device_info.name
            );
            return Ok(Self::single_context_mode(device_id, device_info));
        }

        Ok(Self {
            device_info,
            contexts: HashMap::new(),
            total_sms: device_info.sm_count,
            allocated_sms: 0,
        })
    }

    fn single_context_mode(device_id: i32, info: DeviceInfo) -> Self {
        // Fallback: use default CUDA context with all SMs
        Self {
            device_info: info,
            contexts: HashMap::new(),
            total_sms: info.sm_count,
            allocated_sms: info.sm_count,
        }
    }
}
```

---
*Task ID: M03-S14*
*Layer: Surface*
*Module: 03 - 12-Model Embedding Pipeline*
