<?xml version="1.0" encoding="UTF-8"?>
<task_spec id="M03-L01" version="1.0">
<metadata>
  <title>ModelRegistry Core with Lazy Loading</title>
  <status>ready</status>
  <layer>logic</layer>
  <sequence>1</sequence>
  <implements>PRD: Model management, lazy loading, memory tracking</implements>
  <depends_on>M03-F09, M03-F11, M03-F12</depends_on>
  <estimated_hours>4</estimated_hours>
</metadata>

<context>
Implement ModelRegistry managing all 12 embedding models with lazy loading support.
The registry is the central manager for model lifecycle including loading, unloading,
and access. It enforces concurrent load limits and tracks memory usage to prevent OOM.

Key responsibilities:
- Lazy loading: models loaded on first access
- Concurrent access: thread-safe model retrieval via RwLock
- Memory tracking: prevents loading models that exceed memory budget
- Per-model loading locks: serializes concurrent load requests for same model
- Preload support: optionally preload specified models at initialization
</context>

<definition_of_done>
  <signatures>
```rust
pub struct ModelRegistry {
    models: RwLock<HashMap<ModelId, Arc<dyn EmbeddingModel>>>,
    config: ModelRegistryConfig,
    loading_locks: HashMap<ModelId, Arc<Semaphore>>,
    memory_tracker: RwLock<MemoryTracker>,
}

impl ModelRegistry {
    /// Create new registry with configuration
    pub async fn new(config: ModelRegistryConfig) -> EmbeddingResult<Self>;

    /// Initialize registry, preload configured models
    pub async fn initialize(&self) -> EmbeddingResult<()>;

    /// Get model, loading lazily if needed
    pub async fn get_model(&self, model_id: ModelId) -> EmbeddingResult<Arc<dyn EmbeddingModel>>;

    /// Explicitly load a model
    pub async fn load_model(&self, model_id: ModelId) -> EmbeddingResult<()>;

    /// Unload a model to free memory
    pub async fn unload_model(&self, model_id: ModelId) -> EmbeddingResult<()>;

    /// Check if model is currently loaded
    pub fn is_loaded(&self, model_id: ModelId) -> bool;

    /// List all currently loaded models
    pub fn loaded_models(&self) -> Vec<ModelId>;

    /// Get total memory usage across all loaded models
    pub fn total_memory_usage(&self) -> usize;

    /// Get registry statistics
    pub fn stats(&self) -> RegistryStats;
}

#[derive(Debug, Clone)]
pub struct RegistryStats {
    pub loaded_count: usize,
    pub total_memory_bytes: usize,
    pub load_count: u64,
    pub unload_count: u64,
    pub cache_hits: u64,
}
```
  </signatures>

  <constraints>
    <constraint>Concurrent load requests for same model serialized via per-model Semaphore</constraint>
    <constraint>max_concurrent_loads from config limits parallel model loading</constraint>
    <constraint>Memory tracking prevents OOM by checking can_allocate before load</constraint>
    <constraint>Thread-safe: all public methods safe for concurrent access</constraint>
    <constraint>Lazy loading: get_model triggers load if not already loaded</constraint>
    <constraint>Factory pattern: uses ModelFactory trait to create model instances</constraint>
  </constraints>

  <verification>
    <step>Concurrent get_model calls for same model only load once</step>
    <step>Memory budget enforced: load fails if insufficient memory</step>
    <step>unload_model frees memory tracked by MemoryTracker</step>
    <step>Preload models loaded during initialize()</step>
    <step>stats() returns accurate counters</step>
    <step>Thread-safety: stress test with concurrent access</step>
  </verification>
</definition_of_done>

<files_to_create>
  <file>crates/context-graph-embeddings/src/models/registry.rs</file>
  <file>crates/context-graph-embeddings/src/models/mod.rs</file>
</files_to_create>

<validation_criteria>
  <criterion>cargo check passes</criterion>
  <criterion>cargo test passes</criterion>
  <criterion>No deadlock under concurrent access</criterion>
  <criterion>Memory tracking accurate within 1%</criterion>
</validation_criteria>
</task_spec>
