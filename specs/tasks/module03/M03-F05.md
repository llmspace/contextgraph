# Task Specification: M03-F05

```xml
<task_spec id="M03-F05" version="1.0">
<metadata>
  <title>Define FusedEmbedding Struct (1536D Output)</title>
  <status>ready</status>
  <layer>foundation</layer>
  <sequence>5</sequence>
  <implements>constitution.yaml: embeddings.fused_output</implements>
  <depends_on>M03-F01, M03-F02</depends_on>
  <estimated_hours>2</estimated_hours>
</metadata>

<context>
Implement FusedEmbedding struct - the final 1536D output from FuseMoE fusion.
This is the primary embedding representation used throughout the system for
similarity search, clustering, and downstream tasks.

The struct must capture:
- The 1536D fused vector
- Expert routing information (which experts were selected)
- Expert weights (contribution of each expert)
- Pipeline timing for performance monitoring
- Content hash for caching
</context>

<definition_of_done>
  <signatures>
```rust
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FusedEmbedding {
    pub vector: Vec<f32>,
    pub expert_weights: [f32; 8],
    pub selected_experts: [u8; 2],
    pub pipeline_latency_us: u64,
    pub content_hash: u64,
    /// Optional auxiliary data for late-interaction models (ColBERT per-token vectors)
    /// Stored as serialized blob for Module 4 graph storage
    #[serde(skip_serializing_if = "Option::is_none")]
    pub aux_data: Option<AuxiliaryEmbeddingData>,
}

/// Auxiliary embedding data for models requiring token-level storage
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AuxiliaryEmbeddingData {
    /// Model that produced this auxiliary data
    pub source_model: ModelId,
    /// Per-token embeddings (e.g., ColBERT 128D per token)
    pub token_vectors: Vec<Vec<f32>>,
    /// Token count (excludes padding)
    pub num_tokens: usize,
    /// Serialized blob for efficient storage
    pub blob: Option<Vec<u8>>,
}

impl FusedEmbedding {
    pub const DIMENSION: usize = 1536;
    pub const NUM_EXPERTS: usize = 8;
    pub const TOP_K: usize = 2;

    pub fn new(vector: Vec<f32>, expert_weights: [f32; 8], selected: [u8; 2]) -> EmbeddingResult<Self>;
    pub fn with_aux_data(self, aux_data: AuxiliaryEmbeddingData) -> Self;
    pub fn validate(&self) -> EmbeddingResult<()>;
    pub fn normalize(&mut self);
    pub fn cosine_similarity(&self, other: &FusedEmbedding) -> f32;
    pub fn to_bytes(&self) -> Vec<u8>;
    pub fn from_bytes(bytes: &[u8]) -> EmbeddingResult<Self>;
    /// Check if this embedding has auxiliary token-level data
    pub fn has_aux_data(&self) -> bool;
    /// Get ColBERT token vectors for MaxSim scoring
    pub fn get_token_vectors(&self) -> Option<&Vec<Vec<f32>>>;
    /// Serialize auxiliary data to blob for storage
    pub fn compress_aux_data(&mut self) -> EmbeddingResult<()>;
    /// Deserialize auxiliary data from blob
    pub fn decompress_aux_data(&mut self) -> EmbeddingResult<()>;
}

impl AuxiliaryEmbeddingData {
    pub fn new(source_model: ModelId, token_vectors: Vec<Vec<f32>>) -> Self;
    pub fn to_blob(&self) -> Vec<u8>;
    pub fn from_blob(blob: &[u8]) -> EmbeddingResult<Self>;
    pub fn memory_size(&self) -> usize;
}
```
  </signatures>

  <constraints>
    <constraint>vector.len() must equal DIMENSION (1536)</constraint>
    <constraint>validate() rejects NaN/Inf values in vector</constraint>
    <constraint>expert_weights sum must be approximately 1.0 (within 0.01)</constraint>
    <constraint>selected_experts values must be less than NUM_EXPERTS (0-7)</constraint>
    <constraint>Serde serialization must be compact and efficient</constraint>
    <constraint>aux_data is optional and skipped during JSON serialization when None</constraint>
    <constraint>ColBERT token vectors in aux_data must be 128D each</constraint>
    <constraint>aux_data.blob provides compressed storage for Module 4 graph</constraint>
  </constraints>

  <verification>
    <check>new() validates dimension is exactly 1536</check>
    <check>new() validates expert indices are valid (0-7)</check>
    <check>validate() catches NaN values</check>
    <check>validate() catches Inf values</check>
    <check>validate() verifies expert_weights sum to ~1.0</check>
    <check>normalize() produces unit vector</check>
    <check>cosine_similarity() returns 1.0 for identical vectors</check>
    <check>cosine_similarity() returns 0.0 for orthogonal vectors</check>
    <check>to_bytes() and from_bytes() round-trip correctly</check>
    <check>Serde JSON round-trip works correctly</check>
    <check>aux_data is None by default</check>
    <check>with_aux_data() attaches ColBERT token vectors</check>
    <check>has_aux_data() returns true when aux_data is Some</check>
    <check>compress_aux_data()/decompress_aux_data() round-trip correctly</check>
  </verification>
</definition_of_done>

<files_to_create>
  <file>crates/context-graph-embeddings/src/types/fused.rs</file>
</files_to_create>

<validation_criteria>
  <criterion>cargo check passes</criterion>
  <criterion>cargo test passes</criterion>
  <criterion>Serde derive compiles without issues</criterion>
  <criterion>Binary serialization is compact (approx 6KB per embedding)</criterion>
</validation_criteria>

<binary_format>
Byte layout for to_bytes()/from_bytes():

**Core embedding (fixed size):**
- Bytes 0-6143: vector (1536 * 4 bytes as f32)
- Bytes 6144-6175: expert_weights (8 * 4 bytes as f32)
- Bytes 6176-6177: selected_experts (2 * 1 byte as u8)
- Bytes 6178-6185: pipeline_latency_us (8 bytes as u64)
- Bytes 6186-6193: content_hash (8 bytes as u64)
- Bytes 6194-6197: aux_data_len (4 bytes as u32, 0 if no aux_data)

**Optional auxiliary data (variable size):**
- Bytes 6198+: aux_data blob (compressed token vectors if present)

Core size: 6198 bytes per embedding
With ColBERT aux_data (100 tokens): ~6198 + 51200 bytes = ~57KB
Compressed aux_data (int8 quantized): ~6198 + 12800 bytes = ~19KB
</binary_format>
</task_spec>
```
