# M03-F15: CacheConfig and GpuConfig Structs

```xml
<task_spec id="M03-F15" version="1.0">
<metadata>
  <title>Define CacheConfig and GpuConfig Structs</title>
  <status>ready</status>
  <layer>foundation</layer>
  <sequence>15</sequence>
  <implements>constitution.yaml:embeddings.cache, embeddings.gpu</implements>
  <depends_on>none</depends_on>
  <estimated_hours>1.5</estimated_hours>
</metadata>

<context>
Configuration for:
1. Embedding cache - LRU cache for computed embeddings to avoid recomputation
2. GPU settings - CUDA device configuration for accelerated inference

The cache provides <100us lookup vs ~200ms recomputation.
Target hit rate: >80% under normal workload.
</context>

<definition_of_done>
  <signatures>
```rust
use std::path::PathBuf;
use serde::{Deserialize, Serialize};

/// Configuration for embedding cache.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CacheConfig {
    /// Whether caching is enabled.
    /// Default: true
    pub enabled: bool,

    /// Maximum number of cached embeddings.
    /// Default: 100_000
    pub max_entries: usize,

    /// Maximum cache size in bytes.
    /// Default: 1GB (1_073_741_824)
    pub max_bytes: usize,

    /// Time-to-live for cached entries (None = no expiration).
    /// Default: None
    pub ttl_seconds: Option<u64>,

    /// Eviction policy when cache is full.
    pub eviction_policy: EvictionPolicy,

    /// Whether to persist cache to disk on shutdown.
    /// Default: false
    pub persist_to_disk: bool,

    /// Path for disk persistence (if enabled).
    pub disk_path: Option<PathBuf>,
}

/// Cache eviction policy.
#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize, Default)]
#[serde(rename_all = "snake_case")]
pub enum EvictionPolicy {
    /// Least Recently Used - evict oldest access.
    #[default]
    Lru,

    /// Least Frequently Used - evict lowest access count.
    Lfu,

    /// LRU with TTL consideration.
    TtlLru,

    /// Adaptive Replacement Cache - balanced LRU/LFU.
    Arc,
}

/// Configuration for GPU usage.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct GpuConfig {
    /// Whether GPU acceleration is enabled.
    /// Default: true
    pub enabled: bool,

    /// CUDA device IDs to use.
    /// Default: [0]
    pub device_ids: Vec<u32>,

    /// Fraction of GPU memory to use (0.0-1.0).
    /// Default: 0.9
    pub memory_fraction: f32,

    /// Use CUDA graphs for kernel fusion.
    /// Default: true
    pub use_cuda_graphs: bool,

    /// Enable mixed precision (FP16/BF16) inference.
    /// Default: true
    pub mixed_precision: bool,

    /// Use CUDA 13.1 green contexts for power efficiency.
    /// Default: false (requires CUDA 13.1+)
    pub green_contexts: bool,
}

impl Default for CacheConfig {
    fn default() -> Self {
        Self {
            enabled: true,
            max_entries: 100_000,
            max_bytes: 1_073_741_824, // 1 GB
            ttl_seconds: None,
            eviction_policy: EvictionPolicy::Lru,
            persist_to_disk: false,
            disk_path: None,
        }
    }
}

impl Default for GpuConfig {
    fn default() -> Self {
        Self {
            enabled: true,
            device_ids: vec![0],
            memory_fraction: 0.9,
            use_cuda_graphs: true,
            mixed_precision: true,
            green_contexts: false,
        }
    }
}

impl CacheConfig {
    /// Validate cache configuration.
    pub fn validate(&self) -> Result<(), String> {
        if self.enabled && self.max_entries == 0 {
            return Err("max_entries must be > 0 when cache enabled".to_string());
        }
        if self.enabled && self.max_bytes == 0 {
            return Err("max_bytes must be > 0 when cache enabled".to_string());
        }
        if self.persist_to_disk && self.disk_path.is_none() {
            return Err("disk_path required when persist_to_disk enabled".to_string());
        }
        Ok(())
    }
}

impl GpuConfig {
    /// Validate GPU configuration.
    pub fn validate(&self) -> Result<(), String> {
        if self.enabled && self.device_ids.is_empty() {
            return Err("device_ids cannot be empty when GPU enabled".to_string());
        }
        if self.memory_fraction <= 0.0 || self.memory_fraction > 1.0 {
            return Err("memory_fraction must be in (0.0, 1.0]".to_string());
        }
        Ok(())
    }

    /// Create CPU-only configuration.
    pub fn cpu_only() -> Self {
        Self {
            enabled: false,
            device_ids: vec![],
            memory_fraction: 0.0,
            use_cuda_graphs: false,
            mixed_precision: false,
            green_contexts: false,
        }
    }
}
```
  </signatures>

  <constraints>
    - max_bytes = 1GB default (fits 100K embeddings * 6KB each)
    - memory_fraction in (0.0, 1.0] - reserve 10% for other operations
    - device_ids required when GPU enabled
    - disk_path required when persist_to_disk enabled
    - green_contexts requires CUDA 13.1+ (RTX 5090 target)
    - EvictionPolicy must be Copy for efficiency
  </constraints>

  <verification>
    - Default::default() passes validate() for both structs
    - CacheConfig default max_entries = 100_000
    - CacheConfig default max_bytes = 1GB
    - GpuConfig default device_ids = [0]
    - GpuConfig default memory_fraction = 0.9
    - GpuConfig::cpu_only() has enabled = false
    - All EvictionPolicy variants serialize correctly
  </verification>
</definition_of_done>

<files_to_create>
  <file>crates/context-graph-embeddings/src/config.rs</file>
</files_to_create>

<validation_criteria>
  <criterion>cargo check --package context-graph-embeddings passes</criterion>
  <criterion>cargo test --package context-graph-embeddings passes</criterion>
  <criterion>cargo clippy --package context-graph-embeddings -- -D warnings shows 0 warnings</criterion>
  <criterion>Both configs have working Default and validate()</criterion>
</validation_criteria>
</task_spec>
```

---

## Implementation Notes

### Cache Sizing Calculation
```
Single FusedEmbedding: 1536 * 4 bytes = 6,144 bytes
100K entries: 100,000 * 6,144 = 614,400,000 bytes (~614 MB)
With metadata overhead: ~1 GB
```

### Example TOML
```toml
[cache]
enabled = true
max_entries = 100000
max_bytes = 1073741824
ttl_seconds = 3600
eviction_policy = "lru"
persist_to_disk = false

[gpu]
enabled = true
device_ids = [0]
memory_fraction = 0.9
use_cuda_graphs = true
mixed_precision = true
green_contexts = false
```

### Test Cases
1. `test_cache_default_max_entries` - 100_000
2. `test_cache_default_max_bytes` - 1GB
3. `test_cache_validate_valid` - Default passes
4. `test_cache_validate_persist_without_path` - Returns error
5. `test_gpu_default_device_ids` - [0]
6. `test_gpu_default_memory_fraction` - 0.9
7. `test_gpu_validate_empty_devices` - Returns error
8. `test_gpu_cpu_only` - enabled = false
9. `test_eviction_policy_variants` - All 4 variants

---

*Task ID: M03-F15*
*Module: 03 - 12-Model Embedding Pipeline*
*Layer: Foundation*
*Created: 2026-01-01*
