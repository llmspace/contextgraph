# Task Specification: M03-S02

```xml
<task_spec id="M03-S02" version="1.0">
<metadata>
  <title>PipelineMetrics and HealthStatus</title>
  <status>ready</status>
  <layer>surface</layer>
  <sequence>41</sequence>
  <implements>
    - PRD: Pipeline observability and monitoring
    - PRD: Health check endpoints
    - Constitution: embeddings.pipeline.metrics
  </implements>
  <depends_on>
    - M03-S01 (EmbeddingPipeline Core)
    - M03-F01 (ModelId Enum)
  </depends_on>
  <estimated_hours>1.5</estimated_hours>
</metadata>

<context>
Implement metrics collection and health status types for the EmbeddingPipeline.
These types enable observability into pipeline performance, resource usage, and
operational health. Metrics use atomic counters for lock-free concurrent updates.

PipelineMetrics tracks:
- Total embeddings generated
- Cache hit/miss rates
- Average latency
- Error counts

HealthStatus provides:
- Overall health boolean
- List of loaded models
- GPU memory usage
- Cache size
- Pipeline uptime
</context>

<definition_of_done>
  <signatures>
    <signature>
```rust
#[derive(Debug, Default)]
pub struct PipelineMetrics {
    /// Total embeddings successfully generated
    pub embeddings_generated: AtomicU64,

    /// Cache hits count
    pub cache_hits: AtomicU64,

    /// Cache misses count
    pub cache_misses: AtomicU64,

    /// Rolling average latency in microseconds
    pub avg_latency_us: AtomicU64,

    /// Total error count
    pub errors: AtomicU64,

    /// Per-model latency tracking (microseconds)
    pub model_latencies: [AtomicU64; 12],

    /// Batch processing count
    pub batches_processed: AtomicU64,

    /// Total items in batches
    pub batch_items_processed: AtomicU64,
}
```
    </signature>
    <signature>
```rust
impl PipelineMetrics {
    /// Create new metrics instance
    pub fn new() -> Self;

    /// Record a successful embedding generation
    pub fn record_embedding(&self, latency_us: u64);

    /// Record a cache hit
    pub fn record_cache_hit(&self);

    /// Record a cache miss
    pub fn record_cache_miss(&self);

    /// Record an error
    pub fn record_error(&self);

    /// Record model-specific latency
    pub fn record_model_latency(&self, model_id: ModelId, latency_us: u64);

    /// Record batch processing
    pub fn record_batch(&self, batch_size: usize, total_latency_us: u64);

    /// Get cache hit rate (0.0 to 1.0)
    pub fn cache_hit_rate(&self) -> f64;

    /// Get average latency in microseconds
    pub fn average_latency_us(&self) -> u64;

    /// Get throughput (embeddings per second)
    pub fn throughput(&self) -> f64;

    /// Reset all metrics
    pub fn reset(&self);

    /// Snapshot metrics to serializable struct
    pub fn snapshot(&self) -> MetricsSnapshot;
}
```
    </signature>
    <signature>
```rust
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct MetricsSnapshot {
    pub embeddings_generated: u64,
    pub cache_hits: u64,
    pub cache_misses: u64,
    pub cache_hit_rate: f64,
    pub avg_latency_us: u64,
    pub errors: u64,
    pub model_latencies: HashMap<ModelId, u64>,
    pub batches_processed: u64,
    pub batch_items_processed: u64,
    pub throughput: f64,
    pub timestamp: DateTime<Utc>,
}
```
    </signature>
    <signature>
```rust
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct HealthStatus {
    /// Overall pipeline health
    pub healthy: bool,

    /// List of currently loaded models
    pub models_loaded: Vec<ModelId>,

    /// Models that failed to load
    pub models_failed: Vec<ModelId>,

    /// GPU memory used in bytes
    pub gpu_memory_used: usize,

    /// GPU memory available in bytes
    pub gpu_memory_available: usize,

    /// Number of items in cache
    pub cache_size: usize,

    /// Cache memory usage in bytes
    pub cache_memory_bytes: usize,

    /// Pipeline uptime duration
    pub uptime: Duration,

    /// Time of last successful embedding
    pub last_embed_time: Option<DateTime<Utc>>,

    /// Current error rate (errors per minute)
    pub error_rate: f64,

    /// Component status details
    pub components: ComponentHealth,
}
```
    </signature>
    <signature>
```rust
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ComponentHealth {
    pub model_registry: bool,
    pub batch_processor: bool,
    pub fusemoe: bool,
    pub cache_manager: bool,
    pub gpu_available: bool,
}
```
    </signature>
    <signature>
```rust
impl HealthStatus {
    /// Create new health status
    pub fn new() -> Self;

    /// Check if all components are healthy
    pub fn is_fully_healthy(&self) -> bool;

    /// Get list of unhealthy components
    pub fn unhealthy_components(&self) -> Vec<&'static str>;

    /// Check if minimum viable (can process embeddings)
    pub fn is_minimum_viable(&self) -> bool;
}
```
    </signature>
  </signatures>

  <constraints>
    - Lock-free: Use AtomicU64 for all counters
    - Thread-safe: Safe to call from multiple threads
    - Low overhead: Metric recording must not impact latency
    - Serializable: HealthStatus and MetricsSnapshot must serialize to JSON
    - Accurate: Rolling average must be computed correctly
    - Model tracking: Track per-model latencies using ModelId as index
    - Memory efficient: Use array for model latencies, not HashMap
  </constraints>
</definition_of_done>

<files_to_create>
  <file>crates/context-graph-embeddings/src/pipeline/metrics.rs</file>
</files_to_create>

<validation_criteria>
  <criterion>cargo check passes with no errors</criterion>
  <criterion>cargo clippy passes with no warnings</criterion>
  <criterion>PipelineMetrics is thread-safe (Send + Sync)</criterion>
  <criterion>Atomic operations work correctly under concurrent access</criterion>
  <criterion>HealthStatus serializes to valid JSON</criterion>
  <criterion>MetricsSnapshot serializes to valid JSON</criterion>
  <criterion>cache_hit_rate() returns value between 0.0 and 1.0</criterion>
</validation_criteria>
</task_spec>
```

## Implementation Notes

### Atomic Counter Pattern
```rust
use std::sync::atomic::{AtomicU64, Ordering};

// Recording a metric
self.embeddings_generated.fetch_add(1, Ordering::Relaxed);

// Reading a metric
let count = self.embeddings_generated.load(Ordering::Relaxed);
```

### Rolling Average Calculation
```rust
// Exponential moving average for latency
let alpha = 0.1; // Smoothing factor
let new_avg = (1.0 - alpha) * old_avg + alpha * new_value;
```

### Health Status Criteria
- `healthy = true` when:
  - At least 10 of 12 models loaded
  - GPU memory usage < 90%
  - Error rate < 10/minute
  - All core components (registry, fusemoe) operational

### Throughput Calculation
```rust
// Track start time and calculate embeddings/second
let elapsed = self.start_time.elapsed();
let throughput = embeddings_generated as f64 / elapsed.as_secs_f64();
```

---
*Task ID: M03-S02*
*Layer: Surface*
*Module: 03 - 12-Model Embedding Pipeline*
