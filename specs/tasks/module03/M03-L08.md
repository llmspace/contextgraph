<?xml version="1.0" encoding="UTF-8"?>
<task_spec id="M03-L08" version="1.0">
<metadata>
  <title>Sparse Model (E6 - naver/splade-cocondenser-ensembledistil)</title>
  <status>ready</status>
  <layer>logic</layer>
  <sequence>8</sequence>
  <implements>PRD: E6 Sparse embedding, SPLADE model, ~30K sparse to 1536D projected</implements>
  <depends_on>M03-F09, M03-L01</depends_on>
  <estimated_hours>4</estimated_hours>
</metadata>

<context>
Implement sparse embedding model using naver/splade-cocondenser-ensembledistil
for learned sparse representations. SPLADE produces vocabulary-sized sparse
vectors with approximately 5% non-zero values, which are then projected to
1536D for fusion compatibility.

Model specifications:
- HuggingFace repo: naver/splade-cocondenser-ensembledistil
- Raw output: ~30K sparse (vocabulary size)
- Active values: ~5% non-zero
- Projected output: 1536D dense for FuseMoE
- Latency target: less than 3ms

SPLADE (Sparse Lexical and Expansion Model) learns importance weights for
vocabulary terms, enabling efficient inverted index retrieval while maintaining
semantic understanding through term expansion.
</context>

<definition_of_done>
  <signatures>
```rust
pub struct SparseModel {
    model: SpladeModel,
    tokenizer: Tokenizer,
    projection: Linear, // vocab_size -> 1536
    device: Device,
    config: SingleModelConfig,
    loaded: AtomicBool,
    memory_size: usize,
}

/// Sparse vector representation before projection
#[derive(Debug, Clone)]
pub struct SparseVector {
    pub indices: Vec<u32>,
    pub values: Vec<f32>,
    pub vocab_size: usize,
}

impl SparseModel {
    /// Create new sparse model instance
    pub fn new(model_path: &Path, config: SingleModelConfig) -> EmbeddingResult<Self>;

    /// Get raw sparse representation (for inverted index)
    pub async fn embed_sparse(&self, input: &ModelInput) -> EmbeddingResult<SparseVector>;

    /// Get top-k activated terms
    pub fn top_k_terms(&self, sparse: &SparseVector, k: usize) -> Vec<(String, f32)>;

    /// Sparsity ratio (non-zero / total)
    pub fn sparsity_ratio(&self, sparse: &SparseVector) -> f32;
}

#[async_trait]
impl EmbeddingModel for SparseModel {
    fn model_id(&self) -> ModelId { ModelId::Sparse }
    fn dimension(&self) -> usize { 1536 } // Projected dimension
    fn max_tokens(&self) -> usize { 512 }
    fn supported_inputs(&self) -> &[InputType] { &[InputType::Text] }

    fn is_loaded(&self) -> bool;
    async fn load(&self) -> EmbeddingResult<()>;
    async fn unload(&self) -> EmbeddingResult<()>;

    /// Returns projected 1536D embedding for fusion
    async fn embed(&self, input: &ModelInput) -> EmbeddingResult<ModelEmbedding>;
    async fn embed_batch(&self, inputs: &[ModelInput]) -> EmbeddingResult<Vec<ModelEmbedding>>;

    fn memory_usage_bytes(&self) -> usize;
    fn warmup_complete(&self) -> bool;
}
```
  </signatures>

  <constraints>
    <constraint>Raw output approximately 30K sparse (5% active values)</constraint>
    <constraint>Projects sparse to 1536D via learned linear projection</constraint>
    <constraint>Stores sparse indices for late retrieval optimization</constraint>
    <constraint>embed() returns projected 1536D for fusion compatibility</constraint>
    <constraint>embed_sparse() returns raw sparse for inverted index use</constraint>
    <constraint>dimension() returns 1536 (projected dimension)</constraint>
    <constraint>SPLADE uses log-saturation: log(1 + ReLU(x))</constraint>
    <constraint>Latency target: less than 3ms</constraint>
  </constraints>

  <verification>
    <step>Model loads from local path</step>
    <step>embed() returns 1536D projected vector</step>
    <step>embed_sparse() returns sparse representation</step>
    <step>Sparse vectors have approximately 5% non-zero values</step>
    <step>Top-k terms are interpretable vocabulary words</step>
    <step>Projection layer trained/loaded correctly</step>
    <step>Latency under 3ms</step>
  </verification>
</definition_of_done>

<files_to_create>
  <file>crates/context-graph-embeddings/src/models/pretrained/sparse.rs</file>
</files_to_create>

<validation_criteria>
  <criterion>cargo check passes</criterion>
  <criterion>cargo test passes</criterion>
  <criterion>Integration test with real model weights</criterion>
  <criterion>Sparse encoding verified</criterion>
  <criterion>Projection layer functional</criterion>
  <criterion>Latency benchmark under 3ms P95</criterion>
</validation_criteria>
</task_spec>
