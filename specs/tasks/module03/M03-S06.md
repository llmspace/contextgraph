# Task Specification: M03-S06

```xml
<task_spec id="M03-S06" version="1.0">
<metadata>
  <title>CUDA Kernel Stubs</title>
  <status>ready</status>
  <layer>surface</layer>
  <sequence>45</sequence>
  <implements>
    - PRD: GPU-accelerated embedding operations
    - PRD: FuseMoE CUDA kernels
    - Constitution: cuda.kernels.embedding_operations
  </implements>
  <depends_on>
    - M03-S04 (CUDA Device Trait)
  </depends_on>
  <estimated_hours>2</estimated_hours>
</metadata>

<context>
Define stub kernel interfaces for future CUDA implementation of embedding operations.
These traits establish the API contract for GPU-accelerated operations without
requiring actual CUDA kernel code. Implementations can be CPU fallbacks initially,
with CUDA kernels added later.

Key operations to accelerate:
1. Batch normalization: Normalize embedding vectors
2. Cosine similarity: Compute similarity between embeddings
3. FuseMoE forward: Expert routing and weighted combination
4. Matrix multiplication: General purpose GEMM
5. Softmax: Gating network activation
6. TopK selection: Expert selection in MoE

The trait-based design allows:
- CPU fallback implementations for testing
- Easy swapping between CPU/GPU at runtime
- Benchmarking GPU vs CPU performance
- Gradual GPU optimization
</context>

<definition_of_done>
  <signatures>
    <signature>
```rust
/// Trait for embedding-specific CUDA kernels
pub trait EmbeddingKernel: Send + Sync {
    /// Batch normalize embedding vectors (L2 normalization)
    /// embeddings: [batch_size, dim] flattened
    /// After normalization, each vector has L2 norm = 1.0
    fn batch_normalize(
        &self,
        embeddings: &mut [f32],
        batch_size: usize,
        dim: usize
    ) -> CudaResult<()>;

    /// Compute cosine similarity between two vectors
    fn cosine_similarity(&self, a: &[f32], b: &[f32]) -> CudaResult<f32>;

    /// Batch cosine similarity: compare query against candidates
    /// Returns similarity scores for each candidate
    fn batch_cosine_similarity(
        &self,
        query: &[f32],
        candidates: &[f32],
        num_candidates: usize,
        dim: usize,
    ) -> CudaResult<Vec<f32>>;

    /// FuseMoE forward pass
    /// input: [batch_size, input_dim]
    /// experts: [num_experts, input_dim, output_dim]
    /// weights: [batch_size, num_experts] routing weights
    /// Returns: [batch_size, output_dim]
    fn fusemoe_forward(
        &self,
        input: &[f32],
        experts: &[&[f32]],
        weights: &[f32],
        batch_size: usize,
        input_dim: usize,
        output_dim: usize,
        num_experts: usize,
    ) -> CudaResult<Vec<f32>>;

    /// Get kernel implementation name
    fn name(&self) -> &str;

    /// Check if GPU acceleration is available
    fn is_gpu_accelerated(&self) -> bool;
}
```
    </signature>
    <signature>
```rust
/// Trait for general CUDA compute kernels
pub trait ComputeKernel: Send + Sync {
    /// Matrix multiplication: C = A @ B
    /// A: [m, k], B: [k, n], C: [m, n]
    fn gemm(
        &self,
        a: &[f32],
        b: &[f32],
        c: &mut [f32],
        m: usize,
        k: usize,
        n: usize,
        transpose_a: bool,
        transpose_b: bool,
    ) -> CudaResult<()>;

    /// Softmax over last dimension
    /// input: [batch_size, dim]
    fn softmax(&self, input: &mut [f32], batch_size: usize, dim: usize) -> CudaResult<()>;

    /// TopK selection
    /// Returns (values, indices) for top k elements per row
    fn topk(
        &self,
        input: &[f32],
        k: usize,
        batch_size: usize,
        dim: usize,
    ) -> CudaResult<(Vec<f32>, Vec<usize>)>;

    /// Element-wise addition: out = a + b
    fn add(&self, a: &[f32], b: &[f32], out: &mut [f32]) -> CudaResult<()>;

    /// Element-wise multiplication: out = a * b
    fn mul(&self, a: &[f32], b: &[f32], out: &mut [f32]) -> CudaResult<()>;

    /// GELU activation
    fn gelu(&self, input: &mut [f32]) -> CudaResult<()>;

    /// Layer normalization
    fn layer_norm(
        &self,
        input: &mut [f32],
        gamma: &[f32],
        beta: &[f32],
        eps: f32,
        batch_size: usize,
        dim: usize,
    ) -> CudaResult<()>;
}
```
    </signature>
    <signature>
```rust
/// CPU fallback implementation of EmbeddingKernel
pub struct CpuEmbeddingKernel;

impl EmbeddingKernel for CpuEmbeddingKernel {
    // All methods implemented with CPU code
}
```
    </signature>
    <signature>
```rust
/// CPU fallback implementation of ComputeKernel
pub struct CpuComputeKernel;

impl ComputeKernel for CpuComputeKernel {
    // All methods implemented with CPU code
}
```
    </signature>
    <signature>
```rust
/// Factory for kernel selection
pub struct KernelFactory;

impl KernelFactory {
    /// Get embedding kernel (GPU if available, CPU fallback)
    pub fn embedding_kernel() -> Box<dyn EmbeddingKernel>;

    /// Get compute kernel (GPU if available, CPU fallback)
    pub fn compute_kernel() -> Box<dyn ComputeKernel>;

    /// Force CPU kernel for testing
    pub fn cpu_embedding_kernel() -> CpuEmbeddingKernel;

    /// Force CPU kernel for testing
    pub fn cpu_compute_kernel() -> CpuComputeKernel;
}
```
    </signature>
    <signature>
```rust
/// Kernel configuration
#[derive(Debug, Clone)]
pub struct KernelConfig {
    /// Prefer GPU over CPU
    pub prefer_gpu: bool,

    /// Minimum batch size for GPU (smaller uses CPU)
    pub gpu_batch_threshold: usize,

    /// Enable tensor cores if available
    pub use_tensor_cores: bool,

    /// Use FP16 for compute
    pub use_fp16: bool,
}

impl Default for KernelConfig {
    fn default() -> Self {
        Self {
            prefer_gpu: true,
            gpu_batch_threshold: 8,
            use_tensor_cores: true,
            use_fp16: false,
        }
    }
}
```
    </signature>
  </signatures>

  <constraints>
    - Trait-based: All kernels behind traits for flexibility
    - CPU fallback: Every kernel has CPU implementation
    - Thread-safe: All kernels are Send + Sync
    - No panics: All operations return CudaResult
    - Numerical stability: Handle edge cases (zero vectors, NaN)
    - Memory efficiency: In-place operations where possible
    - SIMD friendly: CPU implementations use SIMD when beneficial
    - Tensor cores: FP16 accumulation option for supported hardware
  </constraints>
</definition_of_done>

<files_to_create>
  <file>crates/context-graph-cuda/src/kernels/mod.rs</file>
  <file>crates/context-graph-cuda/src/kernels/embedding.rs</file>
  <file>crates/context-graph-cuda/src/kernels/compute.rs</file>
  <file>crates/context-graph-cuda/src/kernels/cpu.rs</file>
  <file>crates/context-graph-cuda/src/kernels/factory.rs</file>
</files_to_create>

<validation_criteria>
  <criterion>cargo check passes with no errors</criterion>
  <criterion>cargo clippy passes with no warnings</criterion>
  <criterion>EmbeddingKernel trait is Send + Sync</criterion>
  <criterion>ComputeKernel trait is Send + Sync</criterion>
  <criterion>CpuEmbeddingKernel implements EmbeddingKernel</criterion>
  <criterion>CpuComputeKernel implements ComputeKernel</criterion>
  <criterion>KernelFactory returns valid kernels</criterion>
  <criterion>batch_normalize produces unit vectors</criterion>
  <criterion>cosine_similarity returns value in [-1, 1]</criterion>
</validation_criteria>
</task_spec>
```

## Implementation Notes

### CPU Batch Normalize Implementation
```rust
impl EmbeddingKernel for CpuEmbeddingKernel {
    fn batch_normalize(
        &self,
        embeddings: &mut [f32],
        batch_size: usize,
        dim: usize
    ) -> CudaResult<()> {
        for i in 0..batch_size {
            let start = i * dim;
            let end = start + dim;
            let vec = &mut embeddings[start..end];

            // Compute L2 norm
            let norm: f32 = vec.iter().map(|x| x * x).sum::<f32>().sqrt();

            // Handle zero vector
            if norm > f32::EPSILON {
                for x in vec.iter_mut() {
                    *x /= norm;
                }
            }
        }
        Ok(())
    }

    fn cosine_similarity(&self, a: &[f32], b: &[f32]) -> CudaResult<f32> {
        if a.len() != b.len() {
            return Err(CudaError::InvalidBuffer);
        }

        let dot: f32 = a.iter().zip(b.iter()).map(|(x, y)| x * y).sum();
        let norm_a: f32 = a.iter().map(|x| x * x).sum::<f32>().sqrt();
        let norm_b: f32 = b.iter().map(|x| x * x).sum::<f32>().sqrt();

        if norm_a < f32::EPSILON || norm_b < f32::EPSILON {
            return Ok(0.0);
        }

        Ok(dot / (norm_a * norm_b))
    }

    fn name(&self) -> &str {
        "cpu-embedding-kernel"
    }

    fn is_gpu_accelerated(&self) -> bool {
        false
    }
}
```

### CPU Softmax Implementation
```rust
impl ComputeKernel for CpuComputeKernel {
    fn softmax(&self, input: &mut [f32], batch_size: usize, dim: usize) -> CudaResult<()> {
        for i in 0..batch_size {
            let start = i * dim;
            let end = start + dim;
            let row = &mut input[start..end];

            // Find max for numerical stability
            let max = row.iter().cloned().fold(f32::NEG_INFINITY, f32::max);

            // Compute exp(x - max)
            let mut sum = 0.0f32;
            for x in row.iter_mut() {
                *x = (*x - max).exp();
                sum += *x;
            }

            // Normalize
            for x in row.iter_mut() {
                *x /= sum;
            }
        }
        Ok(())
    }
}
```

### Future CUDA Kernel Signature
```rust
// When implementing actual CUDA kernels:
pub struct CudaEmbeddingKernel {
    device: Arc<dyn CudaDevice>,
    stream: CudaStream,
}

impl EmbeddingKernel for CudaEmbeddingKernel {
    fn batch_normalize(&self, embeddings: &mut [f32], batch_size: usize, dim: usize) -> CudaResult<()> {
        // 1. Copy to GPU
        // 2. Launch normalize kernel
        // 3. Copy back to host
        // 4. Synchronize
        todo!("CUDA implementation")
    }
}
```

### Kernel Selection Logic
```rust
impl KernelFactory {
    pub fn embedding_kernel() -> Box<dyn EmbeddingKernel> {
        #[cfg(feature = "cuda")]
        if is_available() {
            if let Ok(device) = get_device(0) {
                return Box::new(CudaEmbeddingKernel::new(device));
            }
        }

        Box::new(CpuEmbeddingKernel)
    }
}
```

---
*Task ID: M03-S06*
*Layer: Surface*
*Module: 03 - 12-Model Embedding Pipeline*
