# Task Specification: M03-S05

```xml
<task_spec id="M03-S05" version="1.0">
<metadata>
  <title>GPU Memory Pool</title>
  <status>ready</status>
  <layer>surface</layer>
  <sequence>44</sequence>
  <implements>
    - PRD: Efficient GPU memory management
    - PRD: Memory pooling for allocation reuse
    - Constitution: cuda.memory.pooling
  </implements>
  <depends_on>
    - M03-S04 (CUDA Device Trait)
  </depends_on>
  <estimated_hours>3</estimated_hours>
</metadata>

<context>
Implement a GPU memory pool for efficient allocation reuse. The pool maintains
pre-allocated buffers in size buckets, reducing the overhead of frequent
cudaMalloc/cudaFree calls during model inference.

Key features:
1. Bucket-based allocation: Pre-defined size classes for common allocations
2. Lazy allocation: Buffers allocated on first request, reused after return
3. Memory limits: Enforce maximum GPU memory usage (24GB for RTX 5090)
4. Thread-safe: Safe for concurrent allocation/deallocation
5. Statistics: Track allocation patterns for optimization

Bucket sizes optimized for embedding pipeline:
- 4KB: Small tensors, indices
- 16KB: Attention masks
- 64KB: Token embeddings
- 256KB: Layer outputs
- 1MB: Batch embeddings
- 4MB: Model activations
- 16MB: Large batch buffers
</context>

<definition_of_done>
  <signatures>
    <signature>
```rust
/// GPU memory pool with bucket-based allocation
pub struct GpuMemoryPool {
    /// Per-size bucket pools
    pools: HashMap<usize, Vec<GpuBuffer>>,

    /// Device this pool manages
    device_id: u32,

    /// Maximum memory allowed for this pool
    max_memory: usize,

    /// Currently allocated memory
    allocated: AtomicUsize,

    /// Pool statistics
    stats: PoolStats,

    /// Lock for pool operations
    lock: RwLock<()>,
}
```
    </signature>
    <signature>
```rust
impl GpuMemoryPool {
    /// Bucket sizes in bytes
    pub const BUCKET_SIZES: [usize; 7] = [
        4 * 1024,      // 4KB
        16 * 1024,     // 16KB
        64 * 1024,     // 64KB
        256 * 1024,    // 256KB
        1024 * 1024,   // 1MB
        4 * 1024 * 1024,   // 4MB
        16 * 1024 * 1024,  // 16MB
    ];

    /// Create new memory pool for device
    pub fn new(device_id: u32, max_memory: usize) -> CudaResult<Self>;

    /// Create pool with default memory limit (24GB)
    pub fn with_default_limit(device_id: u32) -> CudaResult<Self>;

    /// Allocate buffer of at least `size` bytes
    pub fn allocate(&self, size: usize) -> CudaResult<PooledBuffer>;

    /// Return buffer to pool for reuse
    pub fn deallocate(&self, buffer: PooledBuffer);

    /// Get total allocated memory
    pub fn allocated_bytes(&self) -> usize;

    /// Get available memory in pool
    pub fn available_bytes(&self) -> usize;

    /// Get number of cached buffers per bucket
    pub fn cached_buffers(&self) -> HashMap<usize, usize>;

    /// Clear all cached buffers
    pub fn clear(&self) -> CudaResult<()>;

    /// Shrink pool to target memory usage
    pub fn shrink_to(&self, target_bytes: usize) -> CudaResult<usize>;

    /// Get pool statistics
    pub fn stats(&self) -> PoolStats;

    /// Reset statistics
    pub fn reset_stats(&self);
}
```
    </signature>
    <signature>
```rust
/// Buffer managed by memory pool
pub struct PooledBuffer {
    /// Underlying GPU buffer
    inner: GpuBuffer,

    /// Actual requested size (may be smaller than buffer)
    requested_size: usize,

    /// Bucket size this buffer belongs to
    bucket_size: usize,

    /// Reference to owning pool
    pool: Option<Arc<GpuMemoryPool>>,
}
```
    </signature>
    <signature>
```rust
impl PooledBuffer {
    /// Get the usable size (requested size)
    pub fn size(&self) -> usize;

    /// Get the actual allocated size (bucket size)
    pub fn allocated_size(&self) -> usize;

    /// Get raw pointer
    pub unsafe fn as_ptr(&self) -> *mut std::ffi::c_void;

    /// Get device ID
    pub fn device_id(&self) -> u32;

    /// Detach from pool (will not be returned on drop)
    pub fn detach(self) -> GpuBuffer;
}
```
    </signature>
    <signature>
```rust
impl Drop for PooledBuffer {
    fn drop(&mut self) {
        // Return to pool if attached
    }
}
```
    </signature>
    <signature>
```rust
/// Pool statistics for monitoring
#[derive(Debug, Clone, Default)]
pub struct PoolStats {
    /// Total allocations requested
    pub allocations: AtomicU64,

    /// Allocations served from cache
    pub cache_hits: AtomicU64,

    /// Allocations requiring new GPU allocation
    pub cache_misses: AtomicU64,

    /// Total deallocations (returns to pool)
    pub deallocations: AtomicU64,

    /// Peak memory usage
    pub peak_memory: AtomicUsize,

    /// Bytes allocated from GPU
    pub bytes_from_gpu: AtomicUsize,

    /// Bytes reused from pool
    pub bytes_from_pool: AtomicUsize,
}
```
    </signature>
    <signature>
```rust
impl PoolStats {
    /// Get cache hit rate
    pub fn hit_rate(&self) -> f64;

    /// Get memory efficiency (reused / total)
    pub fn efficiency(&self) -> f64;

    /// Snapshot to serializable struct
    pub fn snapshot(&self) -> PoolStatsSnapshot;
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PoolStatsSnapshot {
    pub allocations: u64,
    pub cache_hits: u64,
    pub cache_misses: u64,
    pub cache_hit_rate: f64,
    pub deallocations: u64,
    pub peak_memory: usize,
    pub bytes_from_gpu: usize,
    pub bytes_from_pool: usize,
    pub efficiency: f64,
}
```
    </signature>
  </signatures>

  <constraints>
    - Thread-safe: Use RwLock for pool access
    - Bucket selection: Round up to next bucket size
    - Memory limit: Fail allocation if would exceed max_memory
    - Return to pool: PooledBuffer returns to pool on drop
    - Leak prevention: Track all allocated buffers
    - Default limit: 24GB for RTX 5090 (leaving 8GB headroom)
    - Over-allocation: Allocate bucket size, track requested size
    - Statistics: All counters use AtomicU64 for lock-free updates
    - Clear operation: Must synchronize GPU before freeing
  </constraints>
</definition_of_done>

<files_to_create>
  <file>crates/context-graph-cuda/src/memory.rs</file>
  <file>crates/context-graph-cuda/src/pool.rs</file>
</files_to_create>

<validation_criteria>
  <criterion>cargo check passes with no errors</criterion>
  <criterion>cargo clippy passes with no warnings</criterion>
  <criterion>GpuMemoryPool is thread-safe (Send + Sync)</criterion>
  <criterion>PooledBuffer returns to pool on drop</criterion>
  <criterion>BUCKET_SIZES contains 7 size classes</criterion>
  <criterion>allocate() returns buffer >= requested size</criterion>
  <criterion>Memory limit is enforced</criterion>
  <criterion>PoolStats counters are atomic</criterion>
</validation_criteria>
</task_spec>
```

## Implementation Notes

### Bucket Selection Algorithm
```rust
fn select_bucket(size: usize) -> Option<usize> {
    for &bucket_size in &Self::BUCKET_SIZES {
        if size <= bucket_size {
            return Some(bucket_size);
        }
    }
    None // Size too large for pooling
}
```

### Allocation Flow
```rust
pub fn allocate(&self, size: usize) -> CudaResult<PooledBuffer> {
    let bucket_size = Self::select_bucket(size)
        .ok_or(CudaError::OutOfMemory {
            requested: size,
            available: self.available_bytes()
        })?;

    // Try to get from pool first
    if let Some(buffer) = self.try_get_cached(bucket_size) {
        self.stats.cache_hits.fetch_add(1, Ordering::Relaxed);
        self.stats.bytes_from_pool.fetch_add(size, Ordering::Relaxed);
        return Ok(PooledBuffer::new(buffer, size, bucket_size, Some(self.clone())));
    }

    // Check memory limit
    if self.allocated.load(Ordering::Relaxed) + bucket_size > self.max_memory {
        return Err(CudaError::OutOfMemory {
            requested: size,
            available: self.available_bytes()
        });
    }

    // Allocate new buffer
    let device = get_device(self.device_id)?;
    let buffer = device.allocate(bucket_size)?;

    self.allocated.fetch_add(bucket_size, Ordering::Relaxed);
    self.stats.cache_misses.fetch_add(1, Ordering::Relaxed);
    self.stats.bytes_from_gpu.fetch_add(size, Ordering::Relaxed);

    Ok(PooledBuffer::new(buffer, size, bucket_size, Some(self.clone())))
}
```

### Return to Pool
```rust
impl Drop for PooledBuffer {
    fn drop(&mut self) {
        if let Some(pool) = self.pool.take() {
            let buffer = std::mem::take(&mut self.inner);
            pool.return_to_pool(buffer, self.bucket_size);
        }
        // If no pool, buffer will be freed via GpuBuffer::drop
    }
}
```

### Memory Pressure Handling
```rust
pub fn shrink_to(&self, target_bytes: usize) -> CudaResult<usize> {
    let _lock = self.lock.write();
    let mut freed = 0;

    // Free cached buffers starting from largest
    for bucket_size in Self::BUCKET_SIZES.iter().rev() {
        while self.allocated.load(Ordering::Relaxed) > target_bytes {
            if let Some(buffer) = self.pools.get_mut(bucket_size)?.pop() {
                get_device(self.device_id)?.deallocate(buffer)?;
                self.allocated.fetch_sub(*bucket_size, Ordering::Relaxed);
                freed += *bucket_size;
            } else {
                break;
            }
        }
    }

    Ok(freed)
}
```

---
*Task ID: M03-S05*
*Layer: Surface*
*Module: 03 - 12-Model Embedding Pipeline*
