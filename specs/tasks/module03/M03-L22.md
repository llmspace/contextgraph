<?xml version="1.0" encoding="UTF-8"?>
<task_spec id="M03-L22" version="1.0">
<metadata>
  <title>FuseMoE Router with Top-K Selection</title>
  <status>ready</status>
  <layer>logic</layer>
  <sequence>22</sequence>
  <implements>PRD-EMB-004: FuseMoE Mixture of Experts Fusion</implements>
  <depends_on>M03-L20, M03-L21</depends_on>
  <estimated_hours>4</estimated_hours>
</metadata>

<context>
Implement the FuseMoE router that combines the gating network and expert pool to
perform top-k expert selection and routing. The router selects the top-2 experts
for each input, renormalizes their weights, and computes the weighted combination
of expert outputs.

The router also implements load balancing loss to prevent expert collapse during
training, where only a few experts are used. The capacity factor limits how many
tokens each expert can process, preventing overload.
</context>

<definition_of_done>
  <signatures>
```rust
pub struct Router {
    gating: GatingNetwork,
    experts: ExpertPool,
    top_k: usize,
    load_balance_coef: f32,
    capacity_factor: f32,
}

pub struct RoutingResult {
    pub selected_experts: Vec<usize>,
    pub expert_weights: Vec<f32>,
    pub all_gate_probs: Vec<f32>,
}

impl Router {
    pub fn new(config: &FusionConfig) -> EmbeddingResult<Self>;

    /// Route input to experts, returning selected experts and weights
    /// Input: [batch_size, input_dim]
    /// Returns: (expert_indices, normalized_weights) per batch item
    pub fn route(&self, input: &Tensor) -> EmbeddingResult<Vec<RoutingResult>>;

    /// Full forward pass: route + expert computation + combination
    /// Input: [batch_size, input_dim]
    /// Output: [batch_size, output_dim (1536)]
    pub fn forward(&self, input: &Tensor) -> EmbeddingResult<Tensor>;

    /// Compute load balancing auxiliary loss for training
    /// gates: [batch_size, num_experts] probabilities from gating network
    pub fn compute_load_balance_loss(&self, gates: &Tensor) -> EmbeddingResult<f32>;

    /// Get top-k value
    pub fn top_k(&self) -> usize;

    /// Get routing statistics for last batch
    pub fn routing_stats(&self) -> RouterStats;
}

pub struct RouterStats {
    pub expert_utilization: [f32; 8],
    pub avg_top1_prob: f32,
    pub avg_top2_prob: f32,
}
```
  </signatures>

  <constraints>
    <constraint>Select top-2 experts (top_k = 2)</constraint>
    <constraint>Renormalize weights to sum to 1.0</constraint>
    <constraint>Load balance loss prevents expert collapse</constraint>
    <constraint>Capacity factor: 1.25x average load per expert</constraint>
    <constraint>Routing is differentiable for training</constraint>
    <constraint>Expert indices stored in RoutingResult for analysis</constraint>
    <constraint>Thread-safe for concurrent inference</constraint>
  </constraints>
</definition_of_done>

<files_to_create>
  <file>crates/context-graph-embeddings/src/fusion/router.rs</file>
</files_to_create>

<validation_criteria>
  <criterion>cargo check passes</criterion>
  <criterion>cargo clippy passes without warnings</criterion>
  <criterion>Unit test: route() selects exactly top_k experts</criterion>
  <criterion>Unit test: weights are renormalized to sum to 1.0</criterion>
  <criterion>Unit test: forward() output shape is [batch, 1536]</criterion>
  <criterion>Unit test: load_balance_loss returns value in [0, 1]</criterion>
  <criterion>Unit test: capacity_factor limits expert load</criterion>
  <criterion>Unit test: routing_stats tracks expert utilization</criterion>
  <criterion>Integration test: full forward pass with real tensors</criterion>
</validation_criteria>

<implementation_notes>
Top-k selection with renormalization:
```rust
fn select_topk(probs: &Tensor, k: usize) -> (Vec<usize>, Vec<f32>) {
    // Get top-k indices and values
    let (values, indices) = probs.topk(k)?;

    // Renormalize weights to sum to 1.0
    let sum = values.sum()?;
    let normalized = (values / sum)?;

    (indices.to_vec1()?, normalized.to_vec1()?)
}
```

Load balancing loss (Switch Transformer style):
```rust
fn load_balance_loss(gates: &Tensor) -> f32 {
    let num_experts = gates.dim(1)?;
    let batch_size = gates.dim(0)? as f32;

    // f_i = fraction of tokens routed to expert i
    let expert_fractions = gates.mean(0)?;  // [num_experts]

    // P_i = mean probability assigned to expert i
    let expert_probs = gates.mean(0)?;

    // Loss = num_experts * sum(f_i * P_i)
    let loss = (num_experts as f32) * (expert_fractions * expert_probs)?.sum()?;
    loss.to_scalar()?
}
```

Capacity factor limits tokens per expert:
- capacity = (batch_size / num_experts) * capacity_factor
- Tokens exceeding capacity are dropped or redistributed
</implementation_notes>
</task_spec>
