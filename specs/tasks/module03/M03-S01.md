# Task Specification: M03-S01

```xml
<task_spec id="M03-S01" version="1.0">
<metadata>
  <title>EmbeddingPipeline Core</title>
  <status>ready</status>
  <layer>surface</layer>
  <sequence>40</sequence>
  <implements>
    - PRD: 12-model embedding pipeline orchestration
    - PRD: E2E embedding latency <200ms P95
    - PRD: Batch throughput >100 items/sec
    - Constitution: embeddings.pipeline.main_entry_point
  </implements>
  <depends_on>
    - M03-L01 (ModelRegistry with Lazy Loading)
    - M03-L17 (BatchProcessor with Dynamic Batching)
    - M03-L19 (CacheManager with LRU Eviction)
    - M03-L23 (FuseMoE Main Fusion Module)
  </depends_on>
  <estimated_hours>5</estimated_hours>
</metadata>

<context>
Implement the main EmbeddingPipeline struct that orchestrates all embedding pipeline
components. This is the primary entry point for the 12-model embedding system,
coordinating cache lookups, parallel model execution across all 12 specialized
embedding models, concatenation, FuseMoE fusion, and result caching.

The pipeline follows this flow:
1. Check cache for existing embedding (content hash lookup)
2. If cache miss, execute all 12 embedding models in parallel via BatchProcessor
3. Concatenate model outputs into 8320D intermediate vector
4. Pass through FuseMoE to produce 1536D unified embedding
5. Store result in cache and return

Performance targets:
- Single embed E2E: <200ms P95
- Batch throughput: >100 items/sec at batch 32
- Cache hit: <1ms return
</context>

<definition_of_done>
  <signatures>
    <signature>
```rust
pub struct EmbeddingPipeline {
    config: EmbeddingConfig,
    registry: Arc<ModelRegistry>,
    batch_processor: Arc<BatchProcessor>,
    fusemoe: Arc<FuseMoE>,
    cache: Arc<CacheManager>,
    initialized: AtomicBool,
}
```
    </signature>
    <signature>
```rust
impl EmbeddingPipeline {
    /// Create new pipeline with configuration
    pub async fn new(config: EmbeddingConfig) -> EmbeddingResult<Self>;

    /// Initialize all models and warm up pipeline
    pub async fn initialize(&self) -> EmbeddingResult<()>;

    /// Embed single text content to 1536D vector
    pub async fn embed(&self, content: &str) -> EmbeddingResult<FusedEmbedding>;

    /// Batch embed multiple texts
    pub async fn embed_batch(&self, contents: &[&str]) -> EmbeddingResult<Vec<FusedEmbedding>>;

    /// Embed arbitrary model input (text, code, image)
    pub async fn embed_input(&self, input: ModelInput) -> EmbeddingResult<FusedEmbedding>;

    /// Health check returning status of all components
    pub async fn health_check(&self) -> HealthStatus;

    /// Graceful shutdown of pipeline
    pub async fn shutdown(&self) -> EmbeddingResult<()>;

    /// Get current pipeline metrics
    pub fn metrics(&self) -> PipelineMetrics;
}
```
    </signature>
  </signatures>

  <constraints>
    - Thread-safe: All public methods must be callable from multiple threads
    - Async: Use tokio for async execution of model inference
    - Cache-first: Always check cache before running models
    - Parallel models: Execute all 12 models concurrently via BatchProcessor
    - Memory safety: Use Arc for shared components
    - Initialization guard: Return NotInitialized error if embed called before initialize
    - Full pipeline: cache check -> 12 models -> concat -> FuseMoE -> cache store
    - E2E latency <200ms single, >100/sec batch
    - Cache hit returns in <1ms
    - Content hash: Use xxhash64 for cache key generation
    - Graceful degradation: Continue with partial models if some fail
  </constraints>
</definition_of_done>

<files_to_create>
  <file>crates/context-graph-embeddings/src/pipeline.rs</file>
  <file>crates/context-graph-embeddings/src/pipeline/mod.rs</file>
</files_to_create>

<validation_criteria>
  <criterion>cargo check passes with no errors</criterion>
  <criterion>cargo clippy passes with no warnings</criterion>
  <criterion>EmbeddingPipeline::new() compiles and initializes</criterion>
  <criterion>EmbeddingPipeline::embed() returns 1536D FusedEmbedding</criterion>
  <criterion>EmbeddingPipeline::embed_batch() processes multiple inputs</criterion>
  <criterion>All Arc wrapped components are thread-safe</criterion>
  <criterion>AtomicBool initialization guard works correctly</criterion>
</validation_criteria>
</task_spec>
```

## Implementation Notes

### Pipeline Flow Diagram
```
Input Text
    |
    v
[Content Hash] --> [Cache Lookup]
    |                   |
    | (miss)            | (hit)
    v                   v
[BatchProcessor]    [Return cached]
    |
    v (parallel)
[12 Embedding Models]
    |
    v
[ConcatenatedEmbedding]
    |
    v
[FuseMoE Fusion]
    |
    v
[FusedEmbedding 1536D]
    |
    v
[Cache Store] --> [Return]
```

### Key Design Decisions
1. Use `Arc<RwLock<>>` for shared mutable state where needed
2. Use `AtomicBool` for initialization flag (lock-free)
3. Delegate model execution to BatchProcessor for batching efficiency
4. Content hash computed once per input for cache key
5. FuseMoE produces final 1536D vector with expert routing info

### Error Handling
- Wrap all model errors in pipeline-level errors
- Log failures but continue with partial results if possible
- Track error counts in PipelineMetrics
- Timeout handling for slow models

---
*Task ID: M03-S01*
*Layer: Surface*
*Module: 03 - 12-Model Embedding Pipeline*
