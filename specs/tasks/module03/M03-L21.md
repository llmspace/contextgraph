<?xml version="1.0" encoding="UTF-8"?>
<task_spec id="M03-L21" version="1.0">
<metadata>
  <title>Expert Networks (8 Experts) for FuseMoE</title>
  <status>ready</status>
  <layer>logic</layer>
  <sequence>21</sequence>
  <implements>PRD-EMB-004: FuseMoE Mixture of Experts Fusion</implements>
  <depends_on>M03-F02, M03-F14</depends_on>
  <estimated_hours>4</estimated_hours>
</metadata>

<context>
Implement the 8 expert networks for FuseMoE fusion. Each expert is a feed-forward
network (FFN) that transforms the concatenated embedding into the final output
dimension. The ExpertPool manages all 8 experts and provides efficient forward
passes for top-k expert selection.

Architecture per expert:
- Input projection: 8320 -> 4096 (shared optionally)
- Hidden layer: 4096 -> 4096 with GELU activation
- Output projection: 4096 -> 1536

The experts can share the input projection layer for efficiency, reducing total
parameter count while maintaining specialization in later layers.
</context>

<definition_of_done>
  <signatures>
```rust
pub struct Expert {
    input_proj: Linear,
    hidden: Linear,
    output_proj: Linear,
    activation: Activation,
}

impl Expert {
    pub fn new(input_dim: usize, hidden_dim: usize, output_dim: usize) -> Self;

    /// Forward pass for single expert
    /// Input: [batch_size, input_dim]
    /// Output: [batch_size, output_dim]
    pub fn forward(&self, input: &Tensor) -> EmbeddingResult<Tensor>;
}

pub struct ExpertPool {
    experts: [Expert; 8],
    shared_input_proj: Option<Linear>,
    num_experts: usize,
}

impl ExpertPool {
    pub fn new(input_dim: usize, hidden_dim: usize, output_dim: usize) -> Self;

    pub fn new_with_shared_input(
        input_dim: usize,
        hidden_dim: usize,
        output_dim: usize
    ) -> Self;

    /// Forward through single expert
    pub fn forward(&self, input: &Tensor, expert_idx: usize) -> EmbeddingResult<Tensor>;

    /// Forward through top-k experts with weighted combination
    /// indices: which experts to use (e.g., [2, 5])
    /// weights: combination weights (e.g., [0.6, 0.4]), must sum to 1.0
    pub fn forward_topk(
        &self,
        input: &Tensor,
        indices: &[usize],
        weights: &[f32]
    ) -> EmbeddingResult<Tensor>;

    /// Get number of experts
    pub fn num_experts(&self) -> usize;

    /// Get total parameter count
    pub fn parameter_count(&self) -> usize;
}

#[derive(Debug, Clone, Copy)]
pub enum Activation {
    Gelu,
    Relu,
    Silu,
}
```
  </signatures>

  <constraints>
    <constraint>Architecture: input_dim(8320) -> hidden(4096) -> hidden(4096) -> output(1536)</constraint>
    <constraint>GELU activation in hidden layer</constraint>
    <constraint>Optional shared input projection for efficiency</constraint>
    <constraint>8 experts total (NUM_EXPERTS constant)</constraint>
    <constraint>forward_topk weights must sum to approximately 1.0</constraint>
    <constraint>Expert indices must be < num_experts</constraint>
    <constraint>Use candle for tensor operations</constraint>
  </constraints>
</definition_of_done>

<files_to_create>
  <file>crates/context-graph-embeddings/src/fusion/experts.rs</file>
</files_to_create>

<validation_criteria>
  <criterion>cargo check passes</criterion>
  <criterion>cargo clippy passes without warnings</criterion>
  <criterion>Unit test: Expert output shape is [batch, 1536]</criterion>
  <criterion>Unit test: ExpertPool.forward() works for each expert index</criterion>
  <criterion>Unit test: forward_topk combines outputs correctly</criterion>
  <criterion>Unit test: forward_topk with weights [1.0, 0.0] equals single expert</criterion>
  <criterion>Unit test: shared input projection reduces parameter count</criterion>
  <criterion>Unit test: invalid expert_idx returns error</criterion>
  <criterion>Benchmark: forward_topk latency for k=2</criterion>
</validation_criteria>

<implementation_notes>
GELU activation (Gaussian Error Linear Unit):
```rust
fn gelu(x: &Tensor) -> Tensor {
    // Approximation: x * 0.5 * (1 + tanh(sqrt(2/pi) * (x + 0.044715 * x^3)))
    candle_nn::Activation::Gelu.forward(x)
}
```

Weighted combination for top-k:
```rust
fn forward_topk(&self, input: &Tensor, indices: &[usize], weights: &[f32]) -> Result<Tensor> {
    let mut output = Tensor::zeros(&[input.dim(0)?, self.output_dim], input.dtype(), input.device())?;
    for (idx, weight) in indices.iter().zip(weights.iter()) {
        let expert_out = self.forward(input, *idx)?;
        output = (output + (expert_out * *weight)?)?;
    }
    Ok(output)
}
```

Parameter count with shared input:
- Without shared: 8 * (8320*4096 + 4096*4096 + 4096*1536) = ~400M params
- With shared: 8320*4096 + 8*(4096*4096 + 4096*1536) = ~180M params
</implementation_notes>
</task_spec>
