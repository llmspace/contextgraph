# Task Specification: M03-S18

```xml
<task_spec id="M03-S18" version="1.0">
<metadata>
  <title>Tracing & Async Instrumentation</title>
  <status>ready</status>
  <layer>surface</layer>
  <sequence>65</sequence>
  <implements>
    - PRD Section 7.8: Performance monitoring and observability
    - Constitution: reliability.performance_debugging
    - Technical Engine: P95 latency target validation (<200ms)
  </implements>
  <depends_on>
    - M03-S01 (EmbeddingPipeline)
    - M03-S17 (Fail-Safe Async Orchestrator)
    - M03-L17 (BatchProcessor)
  </depends_on>
  <estimated_hours>4</estimated_hours>
</metadata>

<context>
Integrate the `tracing` crate with structured spans for debugging async parallel execution.
When the pipeline hits 205ms (failing the 200ms P95 target), aggregate metrics alone cannot
identify WHICH of the 12 models caused the bottleneck for that specific request.

The parallel orchestrator (M03-S17) runs 12 models in a `JoinSet`. Without per-span tracing:
- Metrics show "pipeline took 205ms"
- Cannot determine if it was E5 (Longformer) taking 180ms or E12 (ColBERT) stalling

With tracing spans:
- Each model execution gets a span with timing
- Parent span aggregates child spans
- tokio-console or OpenTelemetry exporters enable real-time debugging
- Request-level trace shows exact breakdown

Key responsibilities:
- Create hierarchical spans for pipeline stages
- Instrument each model's embed() call with named spans
- Add span fields for model ID, input size, batch size
- Support tokio-console for async task visualization
- Optional OpenTelemetry export for production observability
</context>

<definition_of_done>
  <signatures>
```rust
use tracing::{instrument, span, Level, Span};

/// Tracing configuration for embedding pipeline
#[derive(Debug, Clone)]
pub struct TracingConfig {
    pub enabled: bool,
    pub level: TracingLevel,
    pub tokio_console: bool,
    pub otel_endpoint: Option<String>,
    pub sampling_rate: f32,  // 0.0 - 1.0
}

#[derive(Debug, Clone, Copy, Default)]
pub enum TracingLevel {
    /// Only pipeline-level spans
    Minimal,
    /// Pipeline + model-level spans
    #[default]
    Standard,
    /// All spans including batch internals
    Verbose,
}

/// Initialize tracing subsystem
pub fn init_tracing(config: &TracingConfig) -> EmbeddingResult<TracingGuard>;

/// Guard that cleans up tracing on drop
pub struct TracingGuard {
    _console_guard: Option<console_subscriber::ConsoleLayer>,
    _otel_guard: Option<opentelemetry::sdk::trace::Tracer>,
}

/// Instrumented pipeline execution
impl EmbeddingPipeline {
    #[instrument(
        name = "embed_pipeline",
        skip(self, content),
        fields(
            content_len = content.len(),
            request_id = %uuid::Uuid::new_v4(),
        )
    )]
    pub async fn embed(&self, content: &str) -> EmbeddingResult<FusedEmbedding> {
        // Tokenization span
        let _tokenize_span = span!(Level::DEBUG, "tokenize").entered();
        let tokens = self.tokenize(content).await?;
        drop(_tokenize_span);

        // Parallel model execution span
        let _models_span = span!(Level::INFO, "model_execution", model_count = 12).entered();
        let embeddings = self.execute_models(&tokens).await?;
        drop(_models_span);

        // Fusion span
        let _fusion_span = span!(Level::DEBUG, "fusion").entered();
        let fused = self.fuse(embeddings).await?;

        Ok(fused)
    }
}

/// Instrumented model execution
impl dyn EmbeddingModel {
    #[instrument(
        name = "model_embed",
        skip(self, input),
        fields(
            model_id = %self.model_id(),
            input_tokens = input.token_count(),
        )
    )]
    async fn embed_instrumented(&self, input: &PreparedInput) -> EmbeddingResult<ModelEmbedding>;
}

/// Span utilities for JoinSet execution
pub struct ModelSpanContext {
    pub model_id: ModelId,
    pub parent_span: Span,
}

impl ModelSpanContext {
    /// Create child span for model execution within JoinSet
    pub fn enter_model_span(&self) -> tracing::span::EnteredSpan;
}

/// Trace event types for debugging
#[derive(Debug)]
pub enum TraceEvent {
    ModelStarted { model_id: ModelId, timestamp: Instant },
    ModelCompleted { model_id: ModelId, duration_ms: f64 },
    ModelTimeout { model_id: ModelId, after_ms: f64 },
    ModelError { model_id: ModelId, error: String },
    FusionStarted { embedding_count: usize },
    FusionCompleted { output_dim: usize, duration_ms: f64 },
}

/// Debug trace collector for tests
#[cfg(test)]
pub struct TraceCollector {
    events: Arc<Mutex<Vec<TraceEvent>>>,
}
```
  </signatures>

  <constraints>
    - Use `tracing` crate (standard Rust ecosystem)
    - Spans must propagate correctly across async boundaries
    - JoinSet execution: each task gets its own span linked to parent
    - Minimal overhead when disabled (<1μs per span check)
    - Sampling for production (1% of requests at Standard level)
    - tokio-console integration for development debugging
    - OpenTelemetry export optional (behind feature flag)
    - No allocations in hot path when tracing disabled
    - Span fields must be cheap to compute (no string formatting)
  </constraints>

  <verification>
    <step>init_tracing() sets up subscriber correctly</step>
    <step>Pipeline embed() creates parent span with request_id</step>
    <step>Each model execution gets child span with model_id</step>
    <step>Spans visible in tokio-console during local development</step>
    <step>Trace shows which model caused timeout in failure case</step>
    <step>Sampling rate controls span creation in production</step>
    <step>OpenTelemetry export works when configured</step>
    <step>Disabled tracing adds <1μs overhead per embed call</step>
  </verification>
</definition_of_done>

<files_to_create>
  <file>crates/context-graph-embeddings/src/observability/tracing.rs</file>
  <file>crates/context-graph-embeddings/src/observability/spans.rs</file>
  <file>crates/context-graph-embeddings/src/observability/mod.rs</file>
</files_to_create>

<validation_criteria>
  <criterion>cargo check passes</criterion>
  <criterion>cargo test observability::tracing passes</criterion>
  <criterion>tokio-console shows pipeline spans during integration test</criterion>
  <criterion>Trace identifies bottleneck model in artificial slow test</criterion>
  <criterion>Disabled overhead benchmark <1μs per call</criterion>
  <criterion>OpenTelemetry export integration test (when feature enabled)</criterion>
</validation_criteria>
</task_spec>
```

## Implementation Notes

### Subscriber Setup

```rust
use tracing_subscriber::{layer::SubscriberExt, util::SubscriberInitExt, EnvFilter};

pub fn init_tracing(config: &TracingConfig) -> EmbeddingResult<TracingGuard> {
    if !config.enabled {
        return Ok(TracingGuard::noop());
    }

    let filter = EnvFilter::try_from_default_env()
        .unwrap_or_else(|_| EnvFilter::new(match config.level {
            TracingLevel::Minimal => "embedding_pipeline=info",
            TracingLevel::Standard => "embedding_pipeline=debug,model=info",
            TracingLevel::Verbose => "embedding_pipeline=trace",
        }));

    let subscriber = tracing_subscriber::registry().with(filter);

    // Optional tokio-console layer
    let console_guard = if config.tokio_console {
        let console_layer = console_subscriber::spawn();
        subscriber = subscriber.with(console_layer);
        Some(console_layer)
    } else {
        None
    };

    // Optional OpenTelemetry layer
    let otel_guard = if let Some(endpoint) = &config.otel_endpoint {
        let tracer = opentelemetry_otlp::new_pipeline()
            .tracing()
            .with_exporter(
                opentelemetry_otlp::new_exporter()
                    .tonic()
                    .with_endpoint(endpoint)
            )
            .install_batch(opentelemetry::runtime::Tokio)?;

        let otel_layer = tracing_opentelemetry::layer().with_tracer(tracer.clone());
        subscriber = subscriber.with(otel_layer);
        Some(tracer)
    } else {
        None
    };

    subscriber.init();

    Ok(TracingGuard { _console_guard: console_guard, _otel_guard: otel_guard })
}
```

### Instrumented JoinSet Execution

```rust
use tracing::Instrument;

impl AsyncOrchestrator {
    pub async fn execute_all_models(
        &self,
        input: &PreparedInput,
    ) -> EmbeddingResult<Vec<ModelEmbedding>> {
        let parent_span = span!(Level::INFO, "parallel_models", count = 12);

        let mut set = JoinSet::new();

        for model in &self.models {
            let model = model.clone();
            let input = input.clone();
            let model_span = span!(
                parent: &parent_span,
                Level::DEBUG,
                "model",
                model_id = %model.model_id(),
            );

            set.spawn(
                async move {
                    let start = Instant::now();
                    let result = model.embed(&input).await;
                    tracing::debug!(
                        duration_ms = start.elapsed().as_millis() as f64,
                        "model completed"
                    );
                    result
                }
                .instrument(model_span)
            );
        }

        // Collect results with timeout
        let mut results = Vec::with_capacity(12);
        let deadline = Instant::now() + Duration::from_millis(150);

        while let Some(result) = tokio::select! {
            r = set.join_next() => r,
            _ = tokio::time::sleep_until(deadline.into()) => {
                tracing::warn!(
                    remaining = set.len(),
                    "timeout reached, using partial results"
                );
                None
            }
        } {
            match result {
                Ok(Ok(embedding)) => results.push(embedding),
                Ok(Err(e)) => tracing::error!(error = %e, "model failed"),
                Err(e) => tracing::error!(error = %e, "task panicked"),
            }
        }

        Ok(results)
    }
}
```

### Debugging Slow Requests

With tracing enabled, a slow request produces output like:

```
embed_pipeline{request_id=abc-123 content_len=1500}
  tokenize: 2ms
  parallel_models{count=12}
    model{model_id=Semantic}: 45ms
    model{model_id=Causal}: 180ms ← BOTTLENECK
    model{model_id=Code}: 32ms
    model{model_id=Sparse}: 28ms
    ...
  fusion: 3ms
Total: 205ms (exceeded 200ms target due to Causal model)
```

### tokio-console Visualization

```bash
# Terminal 1: Run with tokio-console enabled
TOKIO_CONSOLE=1 cargo run --features tokio-console

# Terminal 2: Connect console
tokio-console
```

Console shows:
- Active async tasks per model
- Task poll times
- Waker statistics
- Resource contention

---
*Task ID: M03-S18*
*Layer: Surface*
*Module: 03 - 12-Model Embedding Pipeline*
